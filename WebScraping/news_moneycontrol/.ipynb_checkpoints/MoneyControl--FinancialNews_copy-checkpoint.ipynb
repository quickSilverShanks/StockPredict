{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from requests import get\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from dateutil import parser\n",
    "import string\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Industry</th>\n",
       "      <th>Last_Price</th>\n",
       "      <th>Change</th>\n",
       "      <th>Change_percent</th>\n",
       "      <th>Mrk_Cap(Rs Cr)</th>\n",
       "      <th>Scrape_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adani Ports</td>\n",
       "      <td>Transport Infrastructure</td>\n",
       "      <td>353.65</td>\n",
       "      <td>-3.25</td>\n",
       "      <td>-0.91</td>\n",
       "      <td>71,852.90</td>\n",
       "      <td>2020-11-03 15:59:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Asian Paints</td>\n",
       "      <td>Paints</td>\n",
       "      <td>2,154.65</td>\n",
       "      <td>-18.20</td>\n",
       "      <td>-0.84</td>\n",
       "      <td>206,673.55</td>\n",
       "      <td>2020-11-03 15:59:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Axis Bank</td>\n",
       "      <td>Bank - Private</td>\n",
       "      <td>534.15</td>\n",
       "      <td>11.50</td>\n",
       "      <td>2.20</td>\n",
       "      <td>163,459.24</td>\n",
       "      <td>2020-11-03 15:59:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bajaj Auto</td>\n",
       "      <td>Automobile - 2 &amp; 3 Wheelers</td>\n",
       "      <td>2,914.85</td>\n",
       "      <td>71.15</td>\n",
       "      <td>2.50</td>\n",
       "      <td>84,346.15</td>\n",
       "      <td>2020-11-03 15:59:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bajaj Finance</td>\n",
       "      <td>Finance - NBFC</td>\n",
       "      <td>3,490.80</td>\n",
       "      <td>71.00</td>\n",
       "      <td>2.08</td>\n",
       "      <td>210,351.19</td>\n",
       "      <td>2020-11-03 15:59:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Company_Name                     Industry Last_Price  Change  \\\n",
       "0    Adani Ports     Transport Infrastructure     353.65   -3.25   \n",
       "1   Asian Paints                       Paints   2,154.65  -18.20   \n",
       "2      Axis Bank               Bank - Private     534.15   11.50   \n",
       "3     Bajaj Auto  Automobile - 2 & 3 Wheelers   2,914.85   71.15   \n",
       "4  Bajaj Finance               Finance - NBFC   3,490.80   71.00   \n",
       "\n",
       "  Change_percent Mrk_Cap(Rs Cr)         Scrape_date  \n",
       "0          -0.91      71,852.90 2020-11-03 15:59:00  \n",
       "1          -0.84     206,673.55 2020-11-03 15:59:00  \n",
       "2           2.20     163,459.24 2020-11-03 15:59:00  \n",
       "3           2.50      84,346.15 2020-11-03 15:59:00  \n",
       "4           2.08     210,351.19 2020-11-03 15:59:00  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scrape the latest Nifty50 Index Composition with previous day details, such as, company names, prices, change etc.\n",
    "\n",
    "getnifty50 = \"https://www.moneycontrol.com/stocks/marketstats/indexcomp.php?optex=NSE&opttopic=indexcomp&index=9\"\n",
    "soup = BeautifulSoup(get(getnifty50).text, 'lxml')\n",
    "composition_n50 = soup.select('table.tbldata14.bdrtpg')[0]\n",
    "\n",
    "Scrape_date = parser.parse(soup.select('div.FR.b_15.PT5')[0].text)\n",
    "Company_Name = [script.text.strip() for script in composition_n50.select(\"a.bl_12\")[2::2]]\n",
    "Industry = [script.text.strip() for script in composition_n50.select(\"a.bl_12\")[3::2]]\n",
    "# urlsplit = [script.get('href').split('/')[-1] for script in composition_n50.select(\"a.bl_12\")[2::2]]\n",
    "\n",
    "Last_Price = [script.text.strip() for script in composition_n50.select('td.brdrgtgry')[2::6]]\n",
    "Change = [script.text.strip() for script in composition_n50.select('td.brdrgtgry')[3::6]]\n",
    "Change_percent = [script.text.strip() for script in composition_n50.select('td.brdrgtgry')[4::6]]\n",
    "Mrk_Cap = [script.text.strip() for script in composition_n50.select('td.brdrgtgry')[5::6]]\n",
    "\n",
    "\n",
    "nifty50_latest = pd.DataFrame({\n",
    "    'Company_Name' : Company_Name,\n",
    "    'Industry' : Industry,\n",
    "#     'urlsplit' : urlsplit,\n",
    "    'Last_Price' : Last_Price,\n",
    "    'Change' : Change,\n",
    "    'Change_percent' : Change_percent,\n",
    "    'Mrk_Cap(Rs Cr)' : Mrk_Cap\n",
    "})\n",
    "\n",
    "nifty50_latest['Scrape_date'] = Scrape_date\n",
    "print(nifty50_latest.shape)\n",
    "nifty50_latest.to_csv(\"nifty50_latest.csv\")\n",
    "nifty50_latest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sr.No.</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Sector</th>\n",
       "      <th>Weightage</th>\n",
       "      <th>thehindu_searchstring</th>\n",
       "      <th>mcontrol_substring</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Reliance Industries Ltd.</td>\n",
       "      <td>Petroleum Products</td>\n",
       "      <td>14.93%</td>\n",
       "      <td>reliance%20petroleum</td>\n",
       "      <td>RI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>HDFC Bank Ltd.</td>\n",
       "      <td>Banks</td>\n",
       "      <td>9.69%</td>\n",
       "      <td>hdfc%20bank</td>\n",
       "      <td>HDF01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Infosys Limited</td>\n",
       "      <td>Software</td>\n",
       "      <td>7.63%</td>\n",
       "      <td>infosys</td>\n",
       "      <td>IT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Housing Development Fin. Corp. Ltd.</td>\n",
       "      <td>Finance</td>\n",
       "      <td>6.44%</td>\n",
       "      <td>hdfc</td>\n",
       "      <td>HDF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Tata Consultancy Services Ltd.</td>\n",
       "      <td>Software</td>\n",
       "      <td>5.41%</td>\n",
       "      <td>tcs</td>\n",
       "      <td>TCS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sr.No.                         Company Name              Sector Weightage  \\\n",
       "0       1             Reliance Industries Ltd.  Petroleum Products    14.93%   \n",
       "1       2                       HDFC Bank Ltd.               Banks     9.69%   \n",
       "2       3                      Infosys Limited            Software     7.63%   \n",
       "3       4  Housing Development Fin. Corp. Ltd.             Finance     6.44%   \n",
       "4       5       Tata Consultancy Services Ltd.            Software     5.41%   \n",
       "\n",
       "  thehindu_searchstring mcontrol_substring  \n",
       "0  reliance%20petroleum                 RI  \n",
       "1           hdfc%20bank              HDF01  \n",
       "2               infosys                 IT  \n",
       "3                  hdfc                HDF  \n",
       "4                   tcs                TCS  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lookup Table with Nifty50 stocks and MoneyControl url sub-strings\n",
    "nifty50_lookuptable = pd.read_csv(\"nifty50_lookuptable.csv\")\n",
    "Substring = [i for i in nifty50_lookuptable['mcontrol_substring']]\n",
    "# cnames = [i for i in nifty50_lookuptable['Company Name']]\n",
    "print(nifty50_lookuptable.shape)\n",
    "nifty50_lookuptable.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize(yr, urlsplit):\n",
    "    '''\n",
    "    Function to obtain total number of result pages, initialize blank news data and\n",
    "    set urls for moneycontrol news search page for the input year 'yr'.\n",
    "    '''\n",
    "    global ticker, url_all, headlines, dates, news, urls, sources\n",
    "    \n",
    "    urlyr = \"https://www.moneycontrol.com/stocks/company_info/stock_news.php?sc_id=\" + urlsplit + \"&durationType=Y&Year={}\"\n",
    "    url = \"https://www.moneycontrol.com/stocks/company_info/stock_news.php?sc_id={}&scat=&pageno={}&next=0&durationType=Y&Year={}&duration=1&news_type=\"\n",
    "    \n",
    "    soup = BeautifulSoup(get(urlyr.format(yr)).text, 'lxml')\n",
    "    ticker = soup.select('div.FL.gry10')[0].text.split('|')[1].split(':')[1].strip()\n",
    "    result_max = len(soup.select('div.pages.MR10.MT15')[0].select('a')) + 1\n",
    "    \n",
    "    url_all = [url.format(urlsplit, i, yr) for i in range(1, result_max+1)]\n",
    "    headlines, dates, news, urls, sources = [], [], [], [], []\n",
    "    print(\"Total number of result pages for\", ticker, \"in the year\", yr, \":\", result_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getnewslinks():\n",
    "    '''\n",
    "    Function to scrape news headlines, urls, publish dates etc.\n",
    "    '''\n",
    "    print(\"[INFO] Extracting Links...\")\n",
    "\n",
    "    for src in tqdm(url_all):\n",
    "\n",
    "        try:\n",
    "            soup = BeautifulSoup(get(src).text, 'lxml')\n",
    "\n",
    "            # Extracts the Headlines\n",
    "            try:\n",
    "                headline = [script.text.strip() for script in soup.select('a.g_14bl')]\n",
    "                headlines.extend(headline)\n",
    "            except:\n",
    "                print('Exception in Headline')\n",
    "                headlines.extend(None)\n",
    "\n",
    "            # Extracts the urls\n",
    "            try:\n",
    "                source = [\"https://www.moneycontrol.com\"+script.get('href') for script in soup.select('a.g_14bl')]\n",
    "                urls.extend(source)\n",
    "            except:\n",
    "                print('Exception in url')\n",
    "                urls.extend(None)\n",
    "\n",
    "            # Extracts the published dates\n",
    "            try:\n",
    "                dateline = [str(parser.parse(script.text.split('|')[1].strip())).split()[0] for script in soup.select('p.PT3.a_10dgry')]\n",
    "                dates.extend(dateline)\n",
    "            except:\n",
    "                print('Exception in dateline')\n",
    "                dates.extend(None)\n",
    "\n",
    "            # Extracts the bylines\n",
    "            try:\n",
    "                bylines = [script.text.strip() for script in soup.select('span.a_2_10bl')]\n",
    "                sources.extend(bylines)\n",
    "            except:\n",
    "                print('Exception in bylines')\n",
    "                sources.extend(None)\n",
    "\n",
    "        except:\n",
    "            print(\"Exception occurred in url : \", src)\n",
    "            break\n",
    "\n",
    "    print(\"[INFO] Links Extracted.\")\n",
    "    print(\"Total No. of Pages to be Scraped = \", len(urls))\n",
    "    print(\"Oldest Available Article: \", min(dates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getarticles(thres=20):\n",
    "    '''\n",
    "    Function to scrape news articles. Any paragraph with words less than 'thres' will not be considered.\n",
    "    '''\n",
    "    print(\"[INFO] Extracting Articles...\")\n",
    "\n",
    "    for src in tqdm(urls):\n",
    "        try:\n",
    "            # Parse the url to NewsPage\n",
    "            soup = BeautifulSoup(get(src).text, 'lxml')\n",
    "\n",
    "            # Extracts the news articles\n",
    "            try:\n",
    "                news_article = '.'.join([scrape.text.strip() for scrape in soup.select(\"div.arti-flow\")[0].select(\"p\")\n",
    "                                         if scrape.text.split() >= thres])\n",
    "                news.append(news_article)\n",
    "            except:\n",
    "                news.append(None)\n",
    "\n",
    "        except:\n",
    "            print(\"Exception occurred in url : \", src)\n",
    "            news.append(None)\n",
    "\n",
    "    print(\"[INFO] Articles Extracted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chkdata():\n",
    "    '''\n",
    "    Function to check for any missing values in the Dataframe and drop it.\n",
    "    '''\n",
    "    global df\n",
    "    df = pd.DataFrame({'Headlines': headlines,\n",
    "                       'Articles': news,\n",
    "                       'Published_Dates': dates,\n",
    "                       'Source_URLs': urls,\n",
    "                       'ByLines' : sources\n",
    "                       })\n",
    "    print(\"Missing Info in Scraped Data :\")\n",
    "    print(df.isna().sum())\n",
    "    df=df.dropna(axis = 0)\n",
    "    print(\"Total Usable Scraped Data : \", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def savefile(tickr,yr):\n",
    "    '''\n",
    "    Function to save the scraped data as pickle file.\n",
    "    '''\n",
    "    # df.to_csv(\"news_mcontrol_\"+ tickr + \"_\" + str(yr) + \".csv\")\n",
    "    df.to_pickle(\"news_mcontrol_\"+ tickr + \"_\" + str(yr) + \".pkl\")\n",
    "    print(\"Data saved for\", tickr, \"for year\",yr, \".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nifty50 Extraction Search Count : 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of result pages for RELIANCE in the year 2020 : 8\n",
      "[INFO] Extracting Links...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|█████████████████████                                                               | 2/8 [00:01<00:04,  1.27it/s]"
     ]
    }
   ],
   "source": [
    "# Scraping 2020 news articles for all the companies listed in Nifty50\n",
    "\n",
    "yr = 2020\n",
    "\n",
    "for i, sstring in enumerate(Substring):\n",
    "    print(\"Nifty50 Extraction Search Count :\",i+1)\n",
    "    initialize(yr, sstring)\n",
    "    getnewslinks()\n",
    "    getarticles()\n",
    "    chkdata()\n",
    "    savefile(ticker, yr)\n",
    "    time.sleep(5)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The pages with blank Articles, if present, might have a different structure."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
