{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from requests import get\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from dateutil import parser\n",
    "import string\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Industry</th>\n",
       "      <th>Last_Price</th>\n",
       "      <th>Change</th>\n",
       "      <th>Change_percent</th>\n",
       "      <th>Mrk_Cap(Rs Cr)</th>\n",
       "      <th>Scrape_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adani Ports</td>\n",
       "      <td>Transport Infrastructure</td>\n",
       "      <td>368.65</td>\n",
       "      <td>7.55</td>\n",
       "      <td>2.09</td>\n",
       "      <td>74,900.53</td>\n",
       "      <td>2020-11-05 15:59:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Asian Paints</td>\n",
       "      <td>Paints</td>\n",
       "      <td>2,238.30</td>\n",
       "      <td>68.85</td>\n",
       "      <td>3.17</td>\n",
       "      <td>214,697.24</td>\n",
       "      <td>2020-11-05 15:59:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Axis Bank</td>\n",
       "      <td>Bank - Private</td>\n",
       "      <td>539.30</td>\n",
       "      <td>14.15</td>\n",
       "      <td>2.69</td>\n",
       "      <td>165,036.05</td>\n",
       "      <td>2020-11-05 15:59:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bajaj Auto</td>\n",
       "      <td>Automobile - 2 &amp; 3 Wheelers</td>\n",
       "      <td>2,949.30</td>\n",
       "      <td>23.20</td>\n",
       "      <td>0.79</td>\n",
       "      <td>85,343.02</td>\n",
       "      <td>2020-11-05 15:59:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bajaj Finance</td>\n",
       "      <td>Finance - NBFC</td>\n",
       "      <td>3,736.90</td>\n",
       "      <td>175.45</td>\n",
       "      <td>4.93</td>\n",
       "      <td>225,180.86</td>\n",
       "      <td>2020-11-05 15:59:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Company_Name                     Industry Last_Price  Change  \\\n",
       "0    Adani Ports     Transport Infrastructure     368.65    7.55   \n",
       "1   Asian Paints                       Paints   2,238.30   68.85   \n",
       "2      Axis Bank               Bank - Private     539.30   14.15   \n",
       "3     Bajaj Auto  Automobile - 2 & 3 Wheelers   2,949.30   23.20   \n",
       "4  Bajaj Finance               Finance - NBFC   3,736.90  175.45   \n",
       "\n",
       "  Change_percent Mrk_Cap(Rs Cr)         Scrape_date  \n",
       "0           2.09      74,900.53 2020-11-05 15:59:00  \n",
       "1           3.17     214,697.24 2020-11-05 15:59:00  \n",
       "2           2.69     165,036.05 2020-11-05 15:59:00  \n",
       "3           0.79      85,343.02 2020-11-05 15:59:00  \n",
       "4           4.93     225,180.86 2020-11-05 15:59:00  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scrape the latest Nifty50 Index Composition with previous day details, such as, company names, prices, change etc.\n",
    "\n",
    "getnifty50 = \"https://www.moneycontrol.com/stocks/marketstats/indexcomp.php?optex=NSE&opttopic=indexcomp&index=9\"\n",
    "soup = BeautifulSoup(get(getnifty50).text, 'lxml')\n",
    "composition_n50 = soup.select('table.tbldata14.bdrtpg')[0]\n",
    "\n",
    "Scrape_date = parser.parse(soup.select('div.FR.b_15.PT5')[0].text)\n",
    "Company_Name = [script.text.strip() for script in composition_n50.select(\"a.bl_12\")[2::2]]\n",
    "Industry = [script.text.strip() for script in composition_n50.select(\"a.bl_12\")[3::2]]\n",
    "# urlsplit = [script.get('href').split('/')[-1] for script in composition_n50.select(\"a.bl_12\")[2::2]]\n",
    "\n",
    "Last_Price = [script.text.strip() for script in composition_n50.select('td.brdrgtgry')[2::6]]\n",
    "Change = [script.text.strip() for script in composition_n50.select('td.brdrgtgry')[3::6]]\n",
    "Change_percent = [script.text.strip() for script in composition_n50.select('td.brdrgtgry')[4::6]]\n",
    "Mrk_Cap = [script.text.strip() for script in composition_n50.select('td.brdrgtgry')[5::6]]\n",
    "\n",
    "\n",
    "nifty50_latest = pd.DataFrame({\n",
    "    'Company_Name' : Company_Name,\n",
    "    'Industry' : Industry,\n",
    "#     'urlsplit' : urlsplit,\n",
    "    'Last_Price' : Last_Price,\n",
    "    'Change' : Change,\n",
    "    'Change_percent' : Change_percent,\n",
    "    'Mrk_Cap(Rs Cr)' : Mrk_Cap\n",
    "})\n",
    "\n",
    "nifty50_latest['Scrape_date'] = Scrape_date\n",
    "print(nifty50_latest.shape)\n",
    "nifty50_latest.to_csv(\"nifty50_latest.csv\")\n",
    "nifty50_latest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sr.No.</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Sector</th>\n",
       "      <th>Weightage</th>\n",
       "      <th>thehindu_searchstring</th>\n",
       "      <th>mcontrol_substring</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Reliance Industries Ltd.</td>\n",
       "      <td>Petroleum Products</td>\n",
       "      <td>14.93%</td>\n",
       "      <td>reliance%20petroleum</td>\n",
       "      <td>RI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>HDFC Bank Ltd.</td>\n",
       "      <td>Banks</td>\n",
       "      <td>9.69%</td>\n",
       "      <td>hdfc%20bank</td>\n",
       "      <td>HDF01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Infosys Limited</td>\n",
       "      <td>Software</td>\n",
       "      <td>7.63%</td>\n",
       "      <td>infosys</td>\n",
       "      <td>IT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Housing Development Fin. Corp. Ltd.</td>\n",
       "      <td>Finance</td>\n",
       "      <td>6.44%</td>\n",
       "      <td>hdfc</td>\n",
       "      <td>HDF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Tata Consultancy Services Ltd.</td>\n",
       "      <td>Software</td>\n",
       "      <td>5.41%</td>\n",
       "      <td>tcs</td>\n",
       "      <td>TCS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sr.No.                         Company Name              Sector Weightage  \\\n",
       "0       1             Reliance Industries Ltd.  Petroleum Products    14.93%   \n",
       "1       2                       HDFC Bank Ltd.               Banks     9.69%   \n",
       "2       3                      Infosys Limited            Software     7.63%   \n",
       "3       4  Housing Development Fin. Corp. Ltd.             Finance     6.44%   \n",
       "4       5       Tata Consultancy Services Ltd.            Software     5.41%   \n",
       "\n",
       "  thehindu_searchstring mcontrol_substring  \n",
       "0  reliance%20petroleum                 RI  \n",
       "1           hdfc%20bank              HDF01  \n",
       "2               infosys                 IT  \n",
       "3                  hdfc                HDF  \n",
       "4                   tcs                TCS  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lookup Table with Nifty50 stocks and MoneyControl url sub-strings\n",
    "nifty50_lookuptable = pd.read_csv(\"nifty50_lookuptable.csv\")\n",
    "Substring = [i for i in nifty50_lookuptable['mcontrol_substring']]\n",
    "# cnames = [i for i in nifty50_lookuptable['Company Name']]\n",
    "print(nifty50_lookuptable.shape)\n",
    "nifty50_lookuptable.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize(yr, urlsplit):\n",
    "    '''\n",
    "    Function to obtain total number of result pages, initialize blank news data and\n",
    "    set urls for moneycontrol news search page for the input year 'yr'.\n",
    "    '''\n",
    "    global ticker, url_all, headlines, dates, news, urls, sources\n",
    "    \n",
    "    urlyr = \"https://www.moneycontrol.com/stocks/company_info/stock_news.php?sc_id=\" + urlsplit + \"&durationType=Y&Year={}\"\n",
    "    url = \"https://www.moneycontrol.com/stocks/company_info/stock_news.php?sc_id={}&scat=&pageno={}&next=0&durationType=Y&Year={}&duration=1&news_type=\"\n",
    "    \n",
    "    soup = BeautifulSoup(get(urlyr.format(yr)).text, 'lxml')\n",
    "    ticker = soup.select('div.FL.gry10')[0].text.split('|')[1].split(':')[1].strip()\n",
    "    result_max = len(soup.select('div.pages.MR10.MT15')[0].select('a')) + 1\n",
    "    \n",
    "    url_all = [url.format(urlsplit, i, yr) for i in range(1, result_max+1)]\n",
    "    headlines, dates, news, urls, sources = [], [], [], [], []\n",
    "    print(\"Total number of result pages for\", ticker, \"in the year\", yr, \":\", result_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getnewslinks():\n",
    "    '''\n",
    "    Function to scrape news headlines, urls, publish dates etc.\n",
    "    '''\n",
    "    print(\"[INFO] Extracting Links...\")\n",
    "\n",
    "    for src in tqdm(url_all):\n",
    "\n",
    "        try:\n",
    "            soup = BeautifulSoup(get(src).text, 'lxml')\n",
    "\n",
    "            # Extracts the Headlines\n",
    "            try:\n",
    "                headline = [script.text.strip() for script in soup.select('a.g_14bl')]\n",
    "                headlines.extend(headline)\n",
    "            except:\n",
    "                print('Exception in Headline')\n",
    "                headlines.extend(None)\n",
    "\n",
    "            # Extracts the urls\n",
    "            try:\n",
    "                source = [\"https://www.moneycontrol.com\"+script.get('href') for script in soup.select('a.g_14bl')]\n",
    "                urls.extend(source)\n",
    "            except:\n",
    "                print('Exception in url')\n",
    "                urls.extend(None)\n",
    "\n",
    "            # Extracts the published dates\n",
    "            try:\n",
    "                dateline = [str(parser.parse(script.text.split('|')[1].strip())).split()[0] for script in soup.select('p.PT3.a_10dgry')]\n",
    "                dates.extend(dateline)\n",
    "            except:\n",
    "                print('Exception in dateline')\n",
    "                dates.extend(None)\n",
    "\n",
    "            # Extracts the bylines\n",
    "            try:\n",
    "                bylines = [script.select('span.a_2_10bl')[0].text.strip() if len(script.select('span.a_2_10bl'))==1 else None\n",
    "                           for script in soup.select('p.PT3.a_10dgry')]\n",
    "                sources.extend(bylines)\n",
    "            except:\n",
    "                print('Exception in bylines')\n",
    "                sources.extend(None)\n",
    "\n",
    "        except:\n",
    "            print(\"Exception occurred in url : \", src)\n",
    "            break\n",
    "\n",
    "    print(\"[INFO] Links Extracted.\")\n",
    "    print(\"Total No. of Pages to be Scraped = \", len(urls))\n",
    "    print(\"Oldest Available Article: \", min(dates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getarticles(thres=7):\n",
    "    '''\n",
    "    Function to scrape news articles. Any paragraph with words less than 'thres' will not be considered.\n",
    "    '''\n",
    "    print(\"[INFO] Extracting Articles...\")\n",
    "\n",
    "    for src in tqdm(urls):\n",
    "        try:\n",
    "            # Parse the url to NewsPage\n",
    "            soup = BeautifulSoup(get(src).text, 'lxml')\n",
    "\n",
    "            # Extracts the news articles\n",
    "            try:\n",
    "                news_article = '.'.join([scrape.text.strip() for scrape in soup.select(\"div.arti-flow\")[0].select(\"p\")\n",
    "                                         if len(scrape.text.split()) >= thres])\n",
    "                news.append(news_article)\n",
    "            except:\n",
    "                news.append(None)\n",
    "\n",
    "        except:\n",
    "            print(\"Exception occurred in url : \", src)\n",
    "            news.append(None)\n",
    "\n",
    "    print(\"[INFO] Articles Extracted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chkdata():\n",
    "    '''\n",
    "    Function to check for any missing values in the Dataframe and drop it.\n",
    "    '''\n",
    "    global df\n",
    "    df = pd.DataFrame({'Headlines': headlines,\n",
    "                       'Articles': news,\n",
    "                       'Published_Dates': dates,\n",
    "                       'Source_URLs': urls,\n",
    "                       'ByLines' : sources\n",
    "                       })\n",
    "    print(\"Missing Info in Scraped Data :\")\n",
    "    print(df.isna().sum())\n",
    "    df=df.dropna(axis = 0)\n",
    "    print(\"Total Usable Scraped Data : \", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def savefile(tickr,yr):\n",
    "    '''\n",
    "    Function to save the scraped data as pickle file.\n",
    "    '''\n",
    "    # df.to_csv(\"news_mcontrol_\"+ tickr + \"_\" + str(yr) + \".csv\")\n",
    "    df.to_pickle(\"news_mcontrol_\"+ tickr + \"_\" + str(yr) + \".pkl\")\n",
    "    print(\"Data saved for\", tickr, \"for year\",yr, \".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nifty50 Extraction Search Count : 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of result pages for RELIANCE in the year 2019 : 7\n",
      "[INFO] Extracting Links...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:04<00:00,  1.54it/s]\n",
      "  0%|                                                                                          | 0/138 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Links Extracted.\n",
      "Total No. of Pages to be Scraped =  138\n",
      "Oldest Available Article:  2019-01-06\n",
      "[INFO] Extracting Articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 138/138 [05:16<00:00,  2.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Articles Extracted.\n",
      "Missing Info in Scraped Data :\n",
      "Headlines          0\n",
      "Articles           7\n",
      "Published_Dates    0\n",
      "Source_URLs        0\n",
      "ByLines            0\n",
      "dtype: int64\n",
      "Total Usable Scraped Data :  (131, 5)\n",
      "Data saved for RELIANCE for year 2019 .\n",
      "Nifty50 Extraction Search Count : 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of result pages for HDFCBANK in the year 2019 : 5\n",
      "[INFO] Extracting Links...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:03<00:00,  1.53it/s]\n",
      "  0%|                                                                                           | 0/92 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Links Extracted.\n",
      "Total No. of Pages to be Scraped =  92\n",
      "Oldest Available Article:  2019-01-14\n",
      "[INFO] Extracting Articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 92/92 [03:34<00:00,  2.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Articles Extracted.\n",
      "Missing Info in Scraped Data :\n",
      "Headlines          0\n",
      "Articles           8\n",
      "Published_Dates    0\n",
      "Source_URLs        0\n",
      "ByLines            0\n",
      "dtype: int64\n",
      "Total Usable Scraped Data :  (84, 5)\n",
      "Data saved for HDFCBANK for year 2019 .\n",
      "Nifty50 Extraction Search Count : 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of result pages for INFY in the year 2019 : 7\n",
      "[INFO] Extracting Links...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:04<00:00,  1.51it/s]\n",
      "  0%|                                                                                          | 0/132 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Links Extracted.\n",
      "Total No. of Pages to be Scraped =  132\n",
      "Oldest Available Article:  2019-01-04\n",
      "[INFO] Extracting Articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 132/132 [05:23<00:00,  2.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Articles Extracted.\n",
      "Missing Info in Scraped Data :\n",
      "Headlines          0\n",
      "Articles           7\n",
      "Published_Dates    0\n",
      "Source_URLs        0\n",
      "ByLines            0\n",
      "dtype: int64\n",
      "Total Usable Scraped Data :  (125, 5)\n",
      "Data saved for INFY for year 2019 .\n",
      "Nifty50 Extraction Search Count : 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of result pages for HDFC in the year 2019 : 3\n",
      "[INFO] Extracting Links...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:02<00:00,  1.45it/s]\n",
      "  0%|                                                                                           | 0/57 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Links Extracted.\n",
      "Total No. of Pages to be Scraped =  57\n",
      "Oldest Available Article:  2019-01-14\n",
      "[INFO] Extracting Articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 57/57 [02:12<00:00,  2.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Articles Extracted.\n",
      "Missing Info in Scraped Data :\n",
      "Headlines          0\n",
      "Articles           3\n",
      "Published_Dates    0\n",
      "Source_URLs        0\n",
      "ByLines            0\n",
      "dtype: int64\n",
      "Total Usable Scraped Data :  (54, 5)\n",
      "Data saved for HDFC for year 2019 .\n",
      "Nifty50 Extraction Search Count : 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of result pages for TCS in the year 2019 : 6\n",
      "[INFO] Extracting Links...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:04<00:00,  1.46it/s]\n",
      "  0%|                                                                                          | 0/110 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Links Extracted.\n",
      "Total No. of Pages to be Scraped =  110\n",
      "Oldest Available Article:  2019-01-08\n",
      "[INFO] Extracting Articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 110/110 [04:18<00:00,  2.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Articles Extracted.\n",
      "Missing Info in Scraped Data :\n",
      "Headlines          0\n",
      "Articles           6\n",
      "Published_Dates    0\n",
      "Source_URLs        0\n",
      "ByLines            0\n",
      "dtype: int64\n",
      "Total Usable Scraped Data :  (104, 5)\n",
      "Data saved for TCS for year 2019 .\n",
      "Nifty50 Extraction Search Count : 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of result pages for ICICIBANK in the year 2019 : 6\n",
      "[INFO] Extracting Links...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:04<00:00,  1.43it/s]\n",
      "  0%|                                                                                          | 0/110 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Links Extracted.\n",
      "Total No. of Pages to be Scraped =  110\n",
      "Oldest Available Article:  2019-01-02\n",
      "[INFO] Extracting Articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 110/110 [04:14<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Articles Extracted.\n",
      "Missing Info in Scraped Data :\n",
      "Headlines          0\n",
      "Articles           3\n",
      "Published_Dates    0\n",
      "Source_URLs        0\n",
      "ByLines            0\n",
      "dtype: int64\n",
      "Total Usable Scraped Data :  (107, 5)\n",
      "Data saved for ICICIBANK for year 2019 .\n",
      "Nifty50 Extraction Search Count : 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of result pages for KOTAKBANK in the year 2019 : 4\n",
      "[INFO] Extracting Links...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:02<00:00,  1.45it/s]\n",
      "  0%|                                                                                           | 0/62 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Links Extracted.\n",
      "Total No. of Pages to be Scraped =  62\n",
      "Oldest Available Article:  2019-01-01\n",
      "[INFO] Extracting Articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 62/62 [02:21<00:00,  2.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Articles Extracted.\n",
      "Missing Info in Scraped Data :\n",
      "Headlines          0\n",
      "Articles           7\n",
      "Published_Dates    0\n",
      "Source_URLs        0\n",
      "ByLines            0\n",
      "dtype: int64\n",
      "Total Usable Scraped Data :  (55, 5)\n",
      "Data saved for KOTAKBANK for year 2019 .\n",
      "Nifty50 Extraction Search Count : 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of result pages for HINDUNILVR in the year 2019 : 5\n",
      "[INFO] Extracting Links...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:09<00:00,  1.92s/it]\n",
      "  0%|                                                                                           | 0/88 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Links Extracted.\n",
      "Total No. of Pages to be Scraped =  88\n",
      "Oldest Available Article:  2019-01-10\n",
      "[INFO] Extracting Articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 88/88 [03:09<00:00,  2.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Articles Extracted.\n",
      "Missing Info in Scraped Data :\n",
      "Headlines           0\n",
      "Articles           11\n",
      "Published_Dates     0\n",
      "Source_URLs         0\n",
      "ByLines             1\n",
      "dtype: int64\n",
      "Total Usable Scraped Data :  (77, 5)\n",
      "Data saved for HINDUNILVR for year 2019 .\n",
      "Nifty50 Extraction Search Count : 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of result pages for ITC in the year 2019 : 4\n",
      "[INFO] Extracting Links...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:02<00:00,  1.35it/s]\n",
      "  0%|                                                                                           | 0/77 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Links Extracted.\n",
      "Total No. of Pages to be Scraped =  77\n",
      "Oldest Available Article:  2019-01-10\n",
      "[INFO] Extracting Articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 77/77 [02:28<00:00,  1.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Articles Extracted.\n",
      "Missing Info in Scraped Data :\n",
      "Headlines          0\n",
      "Articles           2\n",
      "Published_Dates    0\n",
      "Source_URLs        0\n",
      "ByLines            0\n",
      "dtype: int64\n",
      "Total Usable Scraped Data :  (75, 5)\n",
      "Data saved for ITC for year 2019 .\n",
      "Nifty50 Extraction Search Count : 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of result pages for LT in the year 2019 : 7\n",
      "[INFO] Extracting Links...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:28<00:00,  4.10s/it]\n",
      "  0%|                                                                                          | 0/139 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Links Extracted.\n",
      "Total No. of Pages to be Scraped =  139\n",
      "Oldest Available Article:  2019-01-03\n",
      "[INFO] Extracting Articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 139/139 [05:49<00:00,  2.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Articles Extracted.\n",
      "Missing Info in Scraped Data :\n",
      "Headlines          0\n",
      "Articles           8\n",
      "Published_Dates    0\n",
      "Source_URLs        0\n",
      "ByLines            1\n",
      "dtype: int64\n",
      "Total Usable Scraped Data :  (130, 5)\n",
      "Data saved for LT for year 2019 .\n",
      "Nifty50 Extraction Search Count : 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of result pages for AXISBANK in the year 2019 : 5\n",
      "[INFO] Extracting Links...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:26<00:00,  5.23s/it]\n",
      "  0%|                                                                                           | 0/92 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Links Extracted.\n",
      "Total No. of Pages to be Scraped =  92\n",
      "Oldest Available Article:  2019-01-08\n",
      "[INFO] Extracting Articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██████████████████▋                                                               | 21/92 [00:58<04:47,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception occurred in url :  https://www.moneycontrol.com/news/business/ready-âto-âsacrificeâ-growthâ-inâ-some-segmentsâ-to-pursue-sustainability-axis-bank_12845341.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 92/92 [03:55<00:00,  2.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Articles Extracted.\n",
      "Missing Info in Scraped Data :\n",
      "Headlines          0\n",
      "Articles           7\n",
      "Published_Dates    0\n",
      "Source_URLs        0\n",
      "ByLines            0\n",
      "dtype: int64\n",
      "Total Usable Scraped Data :  (85, 5)\n",
      "Data saved for AXISBANK for year 2019 .\n",
      "Nifty50 Extraction Search Count : 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of result pages for BHARTIARTL in the year 2019 : 7\n",
      "[INFO] Extracting Links...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:43<00:00,  6.20s/it]\n",
      "  0%|                                                                                          | 0/127 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Links Extracted.\n",
      "Total No. of Pages to be Scraped =  127\n",
      "Oldest Available Article:  2019-01-04\n",
      "[INFO] Extracting Articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 127/127 [04:58<00:00,  2.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Articles Extracted.\n",
      "Missing Info in Scraped Data :\n",
      "Headlines          0\n",
      "Articles           3\n",
      "Published_Dates    0\n",
      "Source_URLs        0\n",
      "ByLines            0\n",
      "dtype: int64\n",
      "Total Usable Scraped Data :  (124, 5)\n",
      "Data saved for BHARTIARTL for year 2019 .\n",
      "Nifty50 Extraction Search Count : 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of result pages for ASIANPAINT in the year 2019 : 3\n",
      "[INFO] Extracting Links...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:19<00:00,  6.55s/it]\n",
      "  0%|                                                                                           | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Links Extracted.\n",
      "Total No. of Pages to be Scraped =  50\n",
      "Oldest Available Article:  2019-01-10\n",
      "[INFO] Extracting Articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [01:50<00:00,  2.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Articles Extracted.\n",
      "Missing Info in Scraped Data :\n",
      "Headlines          0\n",
      "Articles           6\n",
      "Published_Dates    0\n",
      "Source_URLs        0\n",
      "ByLines            0\n",
      "dtype: int64\n",
      "Total Usable Scraped Data :  (44, 5)\n",
      "Data saved for ASIANPAINT for year 2019 .\n",
      "Nifty50 Extraction Search Count : 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/11 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of result pages for MARUTI in the year 2019 : 11\n",
      "[INFO] Extracting Links...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:07<00:00,  1.47it/s]\n",
      "  0%|                                                                                          | 0/201 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Links Extracted.\n",
      "Total No. of Pages to be Scraped =  201\n",
      "Oldest Available Article:  2019-01-01\n",
      "[INFO] Extracting Articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 201/201 [07:50<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Articles Extracted.\n",
      "Missing Info in Scraped Data :\n",
      "Headlines          0\n",
      "Articles           8\n",
      "Published_Dates    0\n",
      "Source_URLs        0\n",
      "ByLines            1\n",
      "dtype: int64\n",
      "Total Usable Scraped Data :  (192, 5)\n",
      "Data saved for MARUTI for year 2019 .\n",
      "Nifty50 Extraction Search Count : 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of result pages for HCLTECH in the year 2019 : 4\n",
      "[INFO] Extracting Links...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:02<00:00,  1.48it/s]\n",
      "  0%|                                                                                           | 0/70 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Links Extracted.\n",
      "Total No. of Pages to be Scraped =  70\n",
      "Oldest Available Article:  2019-01-12\n",
      "[INFO] Extracting Articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 70/70 [02:44<00:00,  2.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Articles Extracted.\n",
      "Missing Info in Scraped Data :\n",
      "Headlines          0\n",
      "Articles           5\n",
      "Published_Dates    0\n",
      "Source_URLs        0\n",
      "ByLines            0\n",
      "dtype: int64\n",
      "Total Usable Scraped Data :  (65, 5)\n",
      "Data saved for HCLTECH for year 2019 .\n",
      "Nifty50 Extraction Search Count : 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of result pages for BAJFINANCE in the year 2019 : 3\n",
      "[INFO] Extracting Links...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:01<00:00,  1.56it/s]\n",
      "  0%|                                                                                           | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Links Extracted.\n",
      "Total No. of Pages to be Scraped =  49\n",
      "Oldest Available Article:  2019-01-04\n",
      "[INFO] Extracting Articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 49/49 [01:56<00:00,  2.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Articles Extracted.\n",
      "Missing Info in Scraped Data :\n",
      "Headlines          0\n",
      "Articles           6\n",
      "Published_Dates    0\n",
      "Source_URLs        0\n",
      "ByLines            0\n",
      "dtype: int64\n",
      "Total Usable Scraped Data :  (43, 5)\n",
      "Data saved for BAJFINANCE for year 2019 .\n",
      "Nifty50 Extraction Search Count : 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/11 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of result pages for SBIN in the year 2019 : 11\n",
      "[INFO] Extracting Links...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:07<00:00,  1.54it/s]\n",
      "  0%|                                                                                          | 0/206 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Links Extracted.\n",
      "Total No. of Pages to be Scraped =  206\n",
      "Oldest Available Article:  2019-01-07\n",
      "[INFO] Extracting Articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|█▏                                                                                | 3/206 [00:08<09:01,  2.67s/it]"
     ]
    }
   ],
   "source": [
    "# Scraping 2019 news articles for all the companies listed in Nifty50\n",
    "\n",
    "yr = 2019\n",
    "\n",
    "for i, sstring in enumerate(Substring):\n",
    "    print(\"Nifty50 Extraction Search Count :\",i+1)\n",
    "    initialize(yr, sstring)\n",
    "    getnewslinks()\n",
    "    getarticles()\n",
    "    chkdata()\n",
    "    savefile(ticker, yr)\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nifty50 Extraction Search Count : 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/11 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of result pages for SBIN in the year 2019 : 11\n",
      "[INFO] Extracting Links...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:55<00:00,  5.01s/it]\n",
      "  0%|                                                                                          | 0/206 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Links Extracted.\n",
      "Total No. of Pages to be Scraped =  206\n",
      "Oldest Available Article:  2019-01-07\n",
      "[INFO] Extracting Articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 206/206 [08:26<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Articles Extracted.\n",
      "Missing Info in Scraped Data :\n",
      "Headlines          0\n",
      "Articles           5\n",
      "Published_Dates    0\n",
      "Source_URLs        0\n",
      "ByLines            0\n",
      "dtype: int64\n",
      "Total Usable Scraped Data :  (201, 5)\n",
      "Data saved for SBIN for year 2019 .\n",
      "Nifty50 Extraction Search Count : 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of result pages for DRREDDY in the year 2019 : 4\n",
      "[INFO] Extracting Links...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:02<00:00,  1.49it/s]\n",
      "  0%|                                                                                           | 0/67 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Links Extracted.\n",
      "Total No. of Pages to be Scraped =  67\n",
      "Oldest Available Article:  2019-01-03\n",
      "[INFO] Extracting Articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [02:38<00:00,  2.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Articles Extracted.\n",
      "Missing Info in Scraped Data :\n",
      "Headlines          0\n",
      "Articles           4\n",
      "Published_Dates    0\n",
      "Source_URLs        0\n",
      "ByLines            0\n",
      "dtype: int64\n",
      "Total Usable Scraped Data :  (63, 5)\n",
      "Data saved for DRREDDY for year 2019 .\n",
      "Nifty50 Extraction Search Count : 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of result pages for M&M in the year 2019 : 7\n",
      "[INFO] Extracting Links...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:04<00:00,  1.47it/s]\n",
      "  0%|                                                                                          | 0/121 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Links Extracted.\n",
      "Total No. of Pages to be Scraped =  121\n",
      "Oldest Available Article:  2019-01-01\n",
      "[INFO] Extracting Articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 121/121 [05:01<00:00,  2.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Articles Extracted.\n",
      "Missing Info in Scraped Data :\n",
      "Headlines          0\n",
      "Articles           6\n",
      "Published_Dates    0\n",
      "Source_URLs        0\n",
      "ByLines            0\n",
      "dtype: int64\n",
      "Total Usable Scraped Data :  (115, 5)\n",
      "Data saved for M&M for year 2019 .\n",
      "Nifty50 Extraction Search Count : 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of result pages for NESTLEIND in the year 2019 : 2\n",
      "[INFO] Extracting Links...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:14<00:00,  7.13s/it]\n",
      "  0%|                                                                                           | 0/36 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Links Extracted.\n",
      "Total No. of Pages to be Scraped =  36\n",
      "Oldest Available Article:  2019-01-07\n",
      "[INFO] Extracting Articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 36/36 [01:28<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Articles Extracted.\n",
      "Missing Info in Scraped Data :\n",
      "Headlines          0\n",
      "Articles           2\n",
      "Published_Dates    0\n",
      "Source_URLs        0\n",
      "ByLines            0\n",
      "dtype: int64\n",
      "Total Usable Scraped Data :  (34, 5)\n",
      "Data saved for NESTLEIND for year 2019 .\n",
      "Nifty50 Extraction Search Count : 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of result pages for SUNPHARMA in the year 2019 : 4\n",
      "[INFO] Extracting Links...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:02<00:00,  1.55it/s]\n",
      "  0%|                                                                                           | 0/75 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Links Extracted.\n",
      "Total No. of Pages to be Scraped =  75\n",
      "Oldest Available Article:  2019-01-09\n",
      "[INFO] Extracting Articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|████████████████████████████████████████████████████████████████████████████▌     | 70/75 [02:48<00:12,  2.52s/it]"
     ]
    }
   ],
   "source": [
    "# Scraping 2019 news articles for all the companies listed in Nifty50\n",
    "\n",
    "yr = 2019\n",
    "\n",
    "for i, sstring in enumerate(Substring):\n",
    "    if i>=16:\n",
    "        print(\"Nifty50 Extraction Search Count :\",i+1)\n",
    "        initialize(yr, sstring)\n",
    "        getnewslinks()\n",
    "        getarticles()\n",
    "        chkdata()\n",
    "        savefile(ticker, yr)\n",
    "        time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nifty50 Extraction Search Count : 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of result pages for SUNPHARMA in the year 2019 : 4\n",
      "[INFO] Extracting Links...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:07<00:00,  1.95s/it]\n",
      "  0%|                                                                                           | 0/75 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Links Extracted.\n",
      "Total No. of Pages to be Scraped =  75\n",
      "Oldest Available Article:  2019-01-09\n",
      "[INFO] Extracting Articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 75/75 [04:21<00:00,  3.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Articles Extracted.\n",
      "Missing Info in Scraped Data :\n",
      "Headlines          0\n",
      "Articles           1\n",
      "Published_Dates    0\n",
      "Source_URLs        0\n",
      "ByLines            0\n",
      "dtype: int64\n",
      "Total Usable Scraped Data :  (74, 5)\n",
      "Data saved for SUNPHARMA for year 2019 .\n",
      "Nifty50 Extraction Search Count : 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of result pages for TITAN in the year 2019 : 3\n",
      "[INFO] Extracting Links...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:08<00:00,  2.98s/it]\n",
      "  0%|                                                                                           | 0/60 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Links Extracted.\n",
      "Total No. of Pages to be Scraped =  60\n",
      "Oldest Available Article:  2019-01-07\n",
      "[INFO] Extracting Articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 60/60 [03:37<00:00,  3.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Articles Extracted.\n",
      "Missing Info in Scraped Data :\n",
      "Headlines          0\n",
      "Articles           6\n",
      "Published_Dates    0\n",
      "Source_URLs        0\n",
      "ByLines            0\n",
      "dtype: int64\n",
      "Total Usable Scraped Data :  (54, 5)\n",
      "Data saved for TITAN for year 2019 .\n",
      "Nifty50 Extraction Search Count : 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of result pages for TECHM in the year 2019 : 4\n",
      "[INFO] Extracting Links...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:02<00:00,  1.56it/s]\n",
      "  0%|                                                                                           | 0/64 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Links Extracted.\n",
      "Total No. of Pages to be Scraped =  64\n",
      "Oldest Available Article:  2019-01-01\n",
      "[INFO] Extracting Articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 64/64 [02:55<00:00,  2.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Articles Extracted.\n",
      "Missing Info in Scraped Data :\n",
      "Headlines          0\n",
      "Articles           3\n",
      "Published_Dates    0\n",
      "Source_URLs        0\n",
      "ByLines            0\n",
      "dtype: int64\n",
      "Total Usable Scraped Data :  (61, 5)\n",
      "Data saved for TECHM for year 2019 .\n",
      "Nifty50 Extraction Search Count : 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of result pages for ULTRACEMCO in the year 2019 : 3\n",
      "[INFO] Extracting Links...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:07<00:00,  2.37s/it]\n",
      "  0%|                                                                                           | 0/54 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Links Extracted.\n",
      "Total No. of Pages to be Scraped =  54\n",
      "Oldest Available Article:  2019-01-10\n",
      "[INFO] Extracting Articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 54/54 [02:23<00:00,  2.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Articles Extracted.\n",
      "Missing Info in Scraped Data :\n",
      "Headlines          0\n",
      "Articles           3\n",
      "Published_Dates    0\n",
      "Source_URLs        0\n",
      "ByLines            1\n",
      "dtype: int64\n",
      "Total Usable Scraped Data :  (50, 5)\n",
      "Data saved for ULTRACEMCO for year 2019 .\n",
      "Nifty50 Extraction Search Count : 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of result pages for WIPRO in the year 2019 : 4\n",
      "[INFO] Extracting Links...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:21<00:00,  5.41s/it]\n",
      "  0%|                                                                                           | 0/77 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Links Extracted.\n",
      "Total No. of Pages to be Scraped =  77\n",
      "Oldest Available Article:  2019-01-12\n",
      "[INFO] Extracting Articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 77/77 [03:18<00:00,  2.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Articles Extracted.\n",
      "Missing Info in Scraped Data :\n",
      "Headlines          0\n",
      "Articles           4\n",
      "Published_Dates    0\n",
      "Source_URLs        0\n",
      "ByLines            0\n",
      "dtype: int64\n",
      "Total Usable Scraped Data :  (73, 5)\n",
      "Data saved for WIPRO for year 2019 .\n",
      "Nifty50 Extraction Search Count : 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of result pages for BRITANNIA in the year 2019 : 3\n",
      "[INFO] Extracting Links...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:19<00:00,  6.60s/it]\n",
      "  0%|                                                                                           | 0/44 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Links Extracted.\n",
      "Total No. of Pages to be Scraped =  44\n",
      "Oldest Available Article:  2019-01-10\n",
      "[INFO] Extracting Articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 44/44 [02:10<00:00,  2.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Articles Extracted.\n",
      "Missing Info in Scraped Data :\n",
      "Headlines          0\n",
      "Articles           4\n",
      "Published_Dates    0\n",
      "Source_URLs        0\n",
      "ByLines            0\n",
      "dtype: int64\n",
      "Total Usable Scraped Data :  (40, 5)\n",
      "Data saved for BRITANNIA for year 2019 .\n",
      "Nifty50 Extraction Search Count : 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of result pages for HDFCLIFE in the year 2019 : 2\n",
      "[INFO] Extracting Links...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:19<00:00,  9.70s/it]\n",
      "  0%|                                                                                           | 0/37 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Links Extracted.\n",
      "Total No. of Pages to be Scraped =  37\n",
      "Oldest Available Article:  2019-01-14\n",
      "[INFO] Extracting Articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 37/37 [02:00<00:00,  3.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Articles Extracted.\n",
      "Missing Info in Scraped Data :\n",
      "Headlines          0\n",
      "Articles           0\n",
      "Published_Dates    0\n",
      "Source_URLs        0\n",
      "ByLines            0\n",
      "dtype: int64\n",
      "Total Usable Scraped Data :  (37, 5)\n",
      "Data saved for HDFCLIFE for year 2019 .\n",
      "Nifty50 Extraction Search Count : 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of result pages for POWERGRID in the year 2019 : 2\n",
      "[INFO] Extracting Links...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:13<00:00,  6.60s/it]\n",
      "  0%|                                                                                           | 0/32 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Links Extracted.\n",
      "Total No. of Pages to be Scraped =  32\n",
      "Oldest Available Article:  2019-01-14\n",
      "[INFO] Extracting Articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [01:30<00:00,  2.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Articles Extracted.\n",
      "Missing Info in Scraped Data :\n",
      "Headlines          0\n",
      "Articles           0\n",
      "Published_Dates    0\n",
      "Source_URLs        0\n",
      "ByLines            0\n",
      "dtype: int64\n",
      "Total Usable Scraped Data :  (32, 5)\n",
      "Data saved for POWERGRID for year 2019 .\n",
      "Nifty50 Extraction Search Count : 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of result pages for NTPC in the year 2019 : 3\n",
      "[INFO] Extracting Links...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:22<00:00,  7.38s/it]\n",
      "  0%|                                                                                           | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Links Extracted.\n",
      "Total No. of Pages to be Scraped =  50\n",
      "Oldest Available Article:  2019-01-11\n",
      "[INFO] Extracting Articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [02:03<00:00,  2.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Articles Extracted.\n",
      "Missing Info in Scraped Data :\n",
      "Headlines          0\n",
      "Articles           1\n",
      "Published_Dates    0\n",
      "Source_URLs        0\n",
      "ByLines            0\n",
      "dtype: int64\n",
      "Total Usable Scraped Data :  (49, 5)\n",
      "Data saved for NTPC for year 2019 .\n",
      "Nifty50 Extraction Search Count : 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of result pages for HEROMOTOCO in the year 2019 : 5\n",
      "[INFO] Extracting Links...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:30<00:00,  6.12s/it]\n",
      "  0%|                                                                                           | 0/88 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Links Extracted.\n",
      "Total No. of Pages to be Scraped =  88\n",
      "Oldest Available Article:  2019-01-02\n",
      "[INFO] Extracting Articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 88/88 [04:40<00:00,  3.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Articles Extracted.\n",
      "Missing Info in Scraped Data :\n",
      "Headlines          0\n",
      "Articles           3\n",
      "Published_Dates    0\n",
      "Source_URLs        0\n",
      "ByLines            0\n",
      "dtype: int64\n",
      "Total Usable Scraped Data :  (85, 5)\n",
      "Data saved for HEROMOTOCO for year 2019 .\n",
      "Nifty50 Extraction Search Count : 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of result pages for CIPLA in the year 2019 : 3\n",
      "[INFO] Extracting Links...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:20<00:00,  6.90s/it]\n",
      "  0%|                                                                                           | 0/52 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Links Extracted.\n",
      "Total No. of Pages to be Scraped =  52\n",
      "Oldest Available Article:  2019-01-01\n",
      "[INFO] Extracting Articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 52/52 [03:11<00:00,  3.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Articles Extracted.\n",
      "Missing Info in Scraped Data :\n",
      "Headlines          0\n",
      "Articles           0\n",
      "Published_Dates    0\n",
      "Source_URLs        0\n",
      "ByLines            0\n",
      "dtype: int64\n",
      "Total Usable Scraped Data :  (52, 5)\n",
      "Data saved for CIPLA for year 2019 .\n",
      "Nifty50 Extraction Search Count : 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of result pages for DIVISLAB in the year 2019 : 1\n",
      "[INFO] Extracting Links...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:11<00:00, 11.02s/it]\n",
      "  0%|                                                                                           | 0/19 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Links Extracted.\n",
      "Total No. of Pages to be Scraped =  19\n",
      "Oldest Available Article:  2019-01-11\n",
      "[INFO] Extracting Articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [00:52<00:00,  2.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Articles Extracted.\n",
      "Missing Info in Scraped Data :\n",
      "Headlines          0\n",
      "Articles           1\n",
      "Published_Dates    0\n",
      "Source_URLs        0\n",
      "ByLines            0\n",
      "dtype: int64\n",
      "Total Usable Scraped Data :  (18, 5)\n",
      "Data saved for DIVISLAB for year 2019 .\n",
      "Nifty50 Extraction Search Count : 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of result pages for BAJAJ-AUTO in the year 2019 : 6\n",
      "[INFO] Extracting Links...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:36<00:00,  6.12s/it]\n",
      "  0%|                                                                                          | 0/118 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Links Extracted.\n",
      "Total No. of Pages to be Scraped =  118\n",
      "Oldest Available Article:  2019-01-04\n",
      "[INFO] Extracting Articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 118/118 [04:55<00:00,  2.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Articles Extracted.\n",
      "Missing Info in Scraped Data :\n",
      "Headlines          0\n",
      "Articles           6\n",
      "Published_Dates    0\n",
      "Source_URLs        0\n",
      "ByLines            0\n",
      "dtype: int64\n",
      "Total Usable Scraped Data :  (112, 5)\n",
      "Data saved for BAJAJ-AUTO for year 2019 .\n",
      "Nifty50 Extraction Search Count : 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of result pages for BAJAJFINSV in the year 2019 : 2\n",
      "[INFO] Extracting Links...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:13<00:00,  6.65s/it]\n",
      "  0%|                                                                                           | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Links Extracted.\n",
      "Total No. of Pages to be Scraped =  24\n",
      "Oldest Available Article:  2019-01-29\n",
      "[INFO] Extracting Articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [01:20<00:00,  3.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Articles Extracted.\n",
      "Missing Info in Scraped Data :\n",
      "Headlines          0\n",
      "Articles           1\n",
      "Published_Dates    0\n",
      "Source_URLs        0\n",
      "ByLines            0\n",
      "dtype: int64\n",
      "Total Usable Scraped Data :  (23, 5)\n",
      "Data saved for BAJAJFINSV for year 2019 .\n",
      "Nifty50 Extraction Search Count : 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of result pages for SBILIFE in the year 2019 : 1\n",
      "[INFO] Extracting Links...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:09<00:00,  9.46s/it]\n",
      "  0%|                                                                                           | 0/19 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Links Extracted.\n",
      "Total No. of Pages to be Scraped =  19\n",
      "Oldest Available Article:  2019-01-18\n",
      "[INFO] Extracting Articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [00:53<00:00,  2.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Articles Extracted.\n",
      "Missing Info in Scraped Data :\n",
      "Headlines          0\n",
      "Articles           0\n",
      "Published_Dates    0\n",
      "Source_URLs        0\n",
      "ByLines            0\n",
      "dtype: int64\n",
      "Total Usable Scraped Data :  (19, 5)\n",
      "Data saved for SBILIFE for year 2019 .\n",
      "Nifty50 Extraction Search Count : 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of result pages for EICHERMOT in the year 2019 : 4\n",
      "[INFO] Extracting Links...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:27<00:00,  6.78s/it]\n",
      "  0%|                                                                                           | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Links Extracted.\n",
      "Total No. of Pages to be Scraped =  63\n",
      "Oldest Available Article:  2019-01-01\n",
      "[INFO] Extracting Articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 63/63 [02:56<00:00,  2.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Articles Extracted.\n",
      "Missing Info in Scraped Data :\n",
      "Headlines          0\n",
      "Articles           3\n",
      "Published_Dates    0\n",
      "Source_URLs        0\n",
      "ByLines            0\n",
      "dtype: int64\n",
      "Total Usable Scraped Data :  (60, 5)\n",
      "Data saved for EICHERMOT for year 2019 .\n",
      "Nifty50 Extraction Search Count : 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of result pages for INDUSINDBK in the year 2019 : 3\n",
      "[INFO] Extracting Links...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:02<00:00,  1.39it/s]\n",
      "  0%|                                                                                           | 0/58 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Links Extracted.\n",
      "Total No. of Pages to be Scraped =  58\n",
      "Oldest Available Article:  2019-01-08\n",
      "[INFO] Extracting Articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 58/58 [02:59<00:00,  3.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Articles Extracted.\n",
      "Missing Info in Scraped Data :\n",
      "Headlines          0\n",
      "Articles           4\n",
      "Published_Dates    0\n",
      "Source_URLs        0\n",
      "ByLines            0\n",
      "dtype: int64\n",
      "Total Usable Scraped Data :  (54, 5)\n",
      "Data saved for INDUSINDBK for year 2019 .\n",
      "Nifty50 Extraction Search Count : 38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of result pages for GRASIM in the year 2019 : 2\n",
      "[INFO] Extracting Links...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.60it/s]\n",
      "  0%|                                                                                            | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Links Extracted.\n",
      "Total No. of Pages to be Scraped =  1\n",
      "Oldest Available Article:  2019-01-21\n",
      "[INFO] Extracting Articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Articles Extracted.\n",
      "Missing Info in Scraped Data :\n",
      "Headlines          0\n",
      "Articles           0\n",
      "Published_Dates    0\n",
      "Source_URLs        0\n",
      "ByLines            0\n",
      "dtype: int64\n",
      "Total Usable Scraped Data :  (1, 5)\n",
      "Data saved for GRASIM for year 2019 .\n",
      "Nifty50 Extraction Search Count : 39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of result pages for BPCL in the year 2019 : 3\n",
      "[INFO] Extracting Links...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:04<00:00,  1.45s/it]\n",
      "  0%|                                                                                           | 0/47 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Links Extracted.\n",
      "Total No. of Pages to be Scraped =  47\n",
      "Oldest Available Article:  2019-01-11\n",
      "[INFO] Extracting Articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 47/47 [02:30<00:00,  3.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Articles Extracted.\n",
      "Missing Info in Scraped Data :\n",
      "Headlines          0\n",
      "Articles           1\n",
      "Published_Dates    0\n",
      "Source_URLs        0\n",
      "ByLines            0\n",
      "dtype: int64\n",
      "Total Usable Scraped Data :  (46, 5)\n",
      "Data saved for BPCL for year 2019 .\n",
      "Nifty50 Extraction Search Count : 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of result pages for JSWSTEEL in the year 2019 : 4\n",
      "[INFO] Extracting Links...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:24<00:00,  6.20s/it]\n",
      "  0%|                                                                                           | 0/73 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Links Extracted.\n",
      "Total No. of Pages to be Scraped =  73\n",
      "Oldest Available Article:  2019-01-01\n",
      "[INFO] Extracting Articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 73/73 [03:13<00:00,  2.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Articles Extracted.\n",
      "Missing Info in Scraped Data :\n",
      "Headlines          0\n",
      "Articles           2\n",
      "Published_Dates    0\n",
      "Source_URLs        0\n",
      "ByLines            0\n",
      "dtype: int64\n",
      "Total Usable Scraped Data :  (71, 5)\n",
      "Data saved for JSWSTEEL for year 2019 .\n",
      "Nifty50 Extraction Search Count : 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of result pages for UPL in the year 2019 : 2\n",
      "[INFO] Extracting Links...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:13<00:00,  6.72s/it]\n",
      "  0%|                                                                                           | 0/27 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Links Extracted.\n",
      "Total No. of Pages to be Scraped =  27\n",
      "Oldest Available Article:  2019-01-16\n",
      "[INFO] Extracting Articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 27/27 [01:12<00:00,  2.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Articles Extracted.\n",
      "Missing Info in Scraped Data :\n",
      "Headlines          0\n",
      "Articles           1\n",
      "Published_Dates    0\n",
      "Source_URLs        0\n",
      "ByLines            0\n",
      "dtype: int64\n",
      "Total Usable Scraped Data :  (26, 5)\n",
      "Data saved for UPL for year 2019 .\n",
      "Nifty50 Extraction Search Count : 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of result pages for SHREECEM in the year 2019 : 2\n",
      "[INFO] Extracting Links...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.51it/s]\n",
      "  0%|                                                                                           | 0/28 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Links Extracted.\n",
      "Total No. of Pages to be Scraped =  28\n",
      "Oldest Available Article:  2019-01-10\n",
      "[INFO] Extracting Articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 28/28 [01:16<00:00,  2.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Articles Extracted.\n",
      "Missing Info in Scraped Data :\n",
      "Headlines          0\n",
      "Articles           1\n",
      "Published_Dates    0\n",
      "Source_URLs        0\n",
      "ByLines            0\n",
      "dtype: int64\n",
      "Total Usable Scraped Data :  (27, 5)\n",
      "Data saved for SHREECEM for year 2019 .\n",
      "Nifty50 Extraction Search Count : 43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of result pages for TATASTEEL in the year 2019 : 6\n",
      "[INFO] Extracting Links...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:40<00:00,  6.68s/it]\n",
      "  0%|                                                                                          | 0/102 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Links Extracted.\n",
      "Total No. of Pages to be Scraped =  102\n",
      "Oldest Available Article:  2019-01-02\n",
      "[INFO] Extracting Articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 102/102 [04:25<00:00,  2.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Articles Extracted.\n",
      "Missing Info in Scraped Data :\n",
      "Headlines          0\n",
      "Articles           2\n",
      "Published_Dates    0\n",
      "Source_URLs        0\n",
      "ByLines            0\n",
      "dtype: int64\n",
      "Total Usable Scraped Data :  (100, 5)\n",
      "Data saved for TATASTEEL for year 2019 .\n",
      "Nifty50 Extraction Search Count : 44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of result pages for HINDALCO in the year 2019 : 2\n",
      "[INFO] Extracting Links...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:15<00:00,  7.53s/it]\n",
      "  0%|                                                                                           | 0/39 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Links Extracted.\n",
      "Total No. of Pages to be Scraped =  39\n",
      "Oldest Available Article:  2019-01-07\n",
      "[INFO] Extracting Articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 39/39 [01:38<00:00,  2.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Articles Extracted.\n",
      "Missing Info in Scraped Data :\n",
      "Headlines          0\n",
      "Articles           1\n",
      "Published_Dates    0\n",
      "Source_URLs        0\n",
      "ByLines            0\n",
      "dtype: int64\n",
      "Total Usable Scraped Data :  (38, 5)\n",
      "Data saved for HINDALCO for year 2019 .\n",
      "Nifty50 Extraction Search Count : 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of result pages for ADANIPORTS in the year 2019 : 2\n",
      "[INFO] Extracting Links...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:16<00:00,  8.49s/it]\n",
      "  0%|                                                                                           | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Links Extracted.\n",
      "Total No. of Pages to be Scraped =  24\n",
      "Oldest Available Article:  2019-01-03\n",
      "[INFO] Extracting Articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [01:04<00:00,  2.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Articles Extracted.\n",
      "Missing Info in Scraped Data :\n",
      "Headlines          0\n",
      "Articles           1\n",
      "Published_Dates    0\n",
      "Source_URLs        0\n",
      "ByLines            0\n",
      "dtype: int64\n",
      "Total Usable Scraped Data :  (23, 5)\n",
      "Data saved for ADANIPORTS for year 2019 .\n",
      "Nifty50 Extraction Search Count : 46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of result pages for ONGC in the year 2019 : 3\n",
      "[INFO] Extracting Links...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:01<00:00,  1.61it/s]\n",
      "  0%|                                                                                           | 0/47 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Links Extracted.\n",
      "Total No. of Pages to be Scraped =  47\n",
      "Oldest Available Article:  2019-01-06\n",
      "[INFO] Extracting Articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 47/47 [02:14<00:00,  2.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Articles Extracted.\n",
      "Missing Info in Scraped Data :\n",
      "Headlines          0\n",
      "Articles           0\n",
      "Published_Dates    0\n",
      "Source_URLs        0\n",
      "ByLines            0\n",
      "dtype: int64\n",
      "Total Usable Scraped Data :  (47, 5)\n",
      "Data saved for ONGC for year 2019 .\n",
      "Nifty50 Extraction Search Count : 47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of result pages for COALINDIA in the year 2019 : 4\n",
      "[INFO] Extracting Links...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:03<00:00,  1.01it/s]\n",
      "  0%|                                                                                           | 0/76 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Links Extracted.\n",
      "Total No. of Pages to be Scraped =  76\n",
      "Oldest Available Article:  2019-01-01\n",
      "[INFO] Extracting Articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 76/76 [04:01<00:00,  3.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Articles Extracted.\n",
      "Missing Info in Scraped Data :\n",
      "Headlines          0\n",
      "Articles           1\n",
      "Published_Dates    0\n",
      "Source_URLs        0\n",
      "ByLines            0\n",
      "dtype: int64\n",
      "Total Usable Scraped Data :  (75, 5)\n",
      "Data saved for COALINDIA for year 2019 .\n",
      "Nifty50 Extraction Search Count : 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of result pages for TATAMOTORS in the year 2019 : 9\n",
      "[INFO] Extracting Links...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:08<00:00,  1.05it/s]\n",
      "  0%|                                                                                          | 0/172 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Links Extracted.\n",
      "Total No. of Pages to be Scraped =  172\n",
      "Oldest Available Article:  2019-01-03\n",
      "[INFO] Extracting Articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 172/172 [07:17<00:00,  2.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Articles Extracted.\n",
      "Missing Info in Scraped Data :\n",
      "Headlines          0\n",
      "Articles           5\n",
      "Published_Dates    0\n",
      "Source_URLs        0\n",
      "ByLines            1\n",
      "dtype: int64\n",
      "Total Usable Scraped Data :  (166, 5)\n",
      "Data saved for TATAMOTORS for year 2019 .\n",
      "Nifty50 Extraction Search Count : 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of result pages for IOC in the year 2019 : 4\n",
      "[INFO] Extracting Links...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|██████████████████████████████████████████                                          | 2/4 [00:01<00:01,  1.13it/s]\n",
      "  0%|                                                                                           | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception occurred in url :  https://www.moneycontrol.com/stocks/company_info/stock_news.php?sc_id=IOC&scat=&pageno=3&next=0&durationType=Y&Year=2019&duration=1&news_type=\n",
      "[INFO] Links Extracted.\n",
      "Total No. of Pages to be Scraped =  40\n",
      "Oldest Available Article:  2019-05-17\n",
      "[INFO] Extracting Articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [01:45<00:00,  2.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Articles Extracted.\n",
      "Missing Info in Scraped Data :\n",
      "Headlines          0\n",
      "Articles           0\n",
      "Published_Dates    0\n",
      "Source_URLs        0\n",
      "ByLines            0\n",
      "dtype: int64\n",
      "Total Usable Scraped Data :  (40, 5)\n",
      "Data saved for IOC for year 2019 .\n",
      "Nifty50 Extraction Search Count : 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of result pages for GAIL in the year 2019 : 3\n",
      "[INFO] Extracting Links...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:19<00:00,  6.51s/it]\n",
      "  0%|                                                                                           | 0/48 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Links Extracted.\n",
      "Total No. of Pages to be Scraped =  48\n",
      "Oldest Available Article:  2019-01-09\n",
      "[INFO] Extracting Articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 48/48 [02:06<00:00,  2.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Articles Extracted.\n",
      "Missing Info in Scraped Data :\n",
      "Headlines          0\n",
      "Articles           1\n",
      "Published_Dates    0\n",
      "Source_URLs        0\n",
      "ByLines            0\n",
      "dtype: int64\n",
      "Total Usable Scraped Data :  (47, 5)\n",
      "Data saved for GAIL for year 2019 .\n"
     ]
    }
   ],
   "source": [
    "# Scraping 2019 news articles for all the companies listed in Nifty50\n",
    "\n",
    "yr = 2019\n",
    "\n",
    "for i, sstring in enumerate(Substring):\n",
    "    if i>=20:\n",
    "        print(\"Nifty50 Extraction Search Count :\",i+1)\n",
    "        initialize(yr, sstring)\n",
    "        getnewslinks()\n",
    "        getarticles()\n",
    "        chkdata()\n",
    "        savefile(ticker, yr)\n",
    "        time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The pages with blank Articles might have a different structure.\n",
    "# There is a text '\\xa0' in the articles that was '&nbsp;' in the html. This will be replaced by ' ' while preprocessing.\n",
    "# Some pages have no byline. Of these, some have video articles.\n",
    "\n",
    "# Below article url is throwing error due to 'TooManyRedirects: Exceeded 30 redirects.'\n",
    "# https://www.moneycontrol.com/news/business/ready-%C3%A2%C2%80%C2%8Ato-%C3%A2%C2%80%C2%8Asacrifice%C3%A2%C2%80%C2%8A-growth%C3%A2%C2%80%C2%8A-in%C3%A2%C2%80%C2%8A-some-segments%C3%A2%C2%80%C2%8A-to-pursue-sustainability-axis-bank_12845341.html\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
