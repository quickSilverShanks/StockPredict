{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from requests import get\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from dateutil import parser\n",
    "import string\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Industry</th>\n",
       "      <th>Last_Price</th>\n",
       "      <th>Change</th>\n",
       "      <th>Change_percent</th>\n",
       "      <th>Mrk_Cap(Rs Cr)</th>\n",
       "      <th>Scrape_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adani Ports</td>\n",
       "      <td>Transport Infrastructure</td>\n",
       "      <td>353.65</td>\n",
       "      <td>-3.25</td>\n",
       "      <td>-0.91</td>\n",
       "      <td>71,852.90</td>\n",
       "      <td>2020-11-03 15:59:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Asian Paints</td>\n",
       "      <td>Paints</td>\n",
       "      <td>2,154.65</td>\n",
       "      <td>-18.20</td>\n",
       "      <td>-0.84</td>\n",
       "      <td>206,673.55</td>\n",
       "      <td>2020-11-03 15:59:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Axis Bank</td>\n",
       "      <td>Bank - Private</td>\n",
       "      <td>534.15</td>\n",
       "      <td>11.50</td>\n",
       "      <td>2.20</td>\n",
       "      <td>163,459.24</td>\n",
       "      <td>2020-11-03 15:59:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bajaj Auto</td>\n",
       "      <td>Automobile - 2 &amp; 3 Wheelers</td>\n",
       "      <td>2,914.85</td>\n",
       "      <td>71.15</td>\n",
       "      <td>2.50</td>\n",
       "      <td>84,346.15</td>\n",
       "      <td>2020-11-03 15:59:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bajaj Finance</td>\n",
       "      <td>Finance - NBFC</td>\n",
       "      <td>3,490.80</td>\n",
       "      <td>71.00</td>\n",
       "      <td>2.08</td>\n",
       "      <td>210,351.19</td>\n",
       "      <td>2020-11-03 15:59:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Company_Name                     Industry Last_Price  Change  \\\n",
       "0    Adani Ports     Transport Infrastructure     353.65   -3.25   \n",
       "1   Asian Paints                       Paints   2,154.65  -18.20   \n",
       "2      Axis Bank               Bank - Private     534.15   11.50   \n",
       "3     Bajaj Auto  Automobile - 2 & 3 Wheelers   2,914.85   71.15   \n",
       "4  Bajaj Finance               Finance - NBFC   3,490.80   71.00   \n",
       "\n",
       "  Change_percent Mrk_Cap(Rs Cr)         Scrape_date  \n",
       "0          -0.91      71,852.90 2020-11-03 15:59:00  \n",
       "1          -0.84     206,673.55 2020-11-03 15:59:00  \n",
       "2           2.20     163,459.24 2020-11-03 15:59:00  \n",
       "3           2.50      84,346.15 2020-11-03 15:59:00  \n",
       "4           2.08     210,351.19 2020-11-03 15:59:00  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scrape the latest Nifty50 Index Composition with previous day details, such as, company names, prices, change etc.\n",
    "\n",
    "getnifty50 = \"https://www.moneycontrol.com/stocks/marketstats/indexcomp.php?optex=NSE&opttopic=indexcomp&index=9\"\n",
    "soup = BeautifulSoup(get(getnifty50).text, 'lxml')\n",
    "composition_n50 = soup.select('table.tbldata14.bdrtpg')[0]\n",
    "\n",
    "Scrape_date = parser.parse(soup.select('div.FR.b_15.PT5')[0].text)\n",
    "Company_Name = [script.text.strip() for script in composition_n50.select(\"a.bl_12\")[2::2]]\n",
    "Industry = [script.text.strip() for script in composition_n50.select(\"a.bl_12\")[3::2]]\n",
    "# urlsplit = [script.get('href').split('/')[-1] for script in composition_n50.select(\"a.bl_12\")[2::2]]\n",
    "\n",
    "Last_Price = [script.text.strip() for script in composition_n50.select('td.brdrgtgry')[2::6]]\n",
    "Change = [script.text.strip() for script in composition_n50.select('td.brdrgtgry')[3::6]]\n",
    "Change_percent = [script.text.strip() for script in composition_n50.select('td.brdrgtgry')[4::6]]\n",
    "Mrk_Cap = [script.text.strip() for script in composition_n50.select('td.brdrgtgry')[5::6]]\n",
    "\n",
    "\n",
    "nifty50_latest = pd.DataFrame({\n",
    "    'Company_Name' : Company_Name,\n",
    "    'Industry' : Industry,\n",
    "#     'urlsplit' : urlsplit,\n",
    "    'Last_Price' : Last_Price,\n",
    "    'Change' : Change,\n",
    "    'Change_percent' : Change_percent,\n",
    "    'Mrk_Cap(Rs Cr)' : Mrk_Cap\n",
    "})\n",
    "\n",
    "nifty50_latest['Scrape_date'] = Scrape_date\n",
    "print(nifty50_latest.shape)\n",
    "nifty50_latest.to_csv(\"nifty50_latest.csv\")\n",
    "nifty50_latest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sr.No.</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Sector</th>\n",
       "      <th>Weightage</th>\n",
       "      <th>thehindu_searchstring</th>\n",
       "      <th>mcontrol_substring</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Reliance Industries Ltd.</td>\n",
       "      <td>Petroleum Products</td>\n",
       "      <td>14.93%</td>\n",
       "      <td>reliance%20petroleum</td>\n",
       "      <td>RI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>HDFC Bank Ltd.</td>\n",
       "      <td>Banks</td>\n",
       "      <td>9.69%</td>\n",
       "      <td>hdfc%20bank</td>\n",
       "      <td>HDF01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Infosys Limited</td>\n",
       "      <td>Software</td>\n",
       "      <td>7.63%</td>\n",
       "      <td>infosys</td>\n",
       "      <td>IT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Housing Development Fin. Corp. Ltd.</td>\n",
       "      <td>Finance</td>\n",
       "      <td>6.44%</td>\n",
       "      <td>hdfc</td>\n",
       "      <td>HDF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Tata Consultancy Services Ltd.</td>\n",
       "      <td>Software</td>\n",
       "      <td>5.41%</td>\n",
       "      <td>tcs</td>\n",
       "      <td>TCS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sr.No.                         Company Name              Sector Weightage  \\\n",
       "0       1             Reliance Industries Ltd.  Petroleum Products    14.93%   \n",
       "1       2                       HDFC Bank Ltd.               Banks     9.69%   \n",
       "2       3                      Infosys Limited            Software     7.63%   \n",
       "3       4  Housing Development Fin. Corp. Ltd.             Finance     6.44%   \n",
       "4       5       Tata Consultancy Services Ltd.            Software     5.41%   \n",
       "\n",
       "  thehindu_searchstring mcontrol_substring  \n",
       "0  reliance%20petroleum                 RI  \n",
       "1           hdfc%20bank              HDF01  \n",
       "2               infosys                 IT  \n",
       "3                  hdfc                HDF  \n",
       "4                   tcs                TCS  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lookup Table with Nifty50 stocks and MoneyControl url sub-strings\n",
    "nifty50_lookuptable = pd.read_csv(\"nifty50_lookuptable.csv\")\n",
    "Substring = [i for i in nifty50_lookuptable['mcontrol_substring']]\n",
    "# cnames = [i for i in nifty50_lookuptable['Company Name']]\n",
    "print(nifty50_lookuptable.shape)\n",
    "nifty50_lookuptable.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize(yr, urlsplit):\n",
    "    '''\n",
    "    Function to obtain total number of result pages, initialize blank news data and\n",
    "    set urls for moneycontrol news search page for the input year 'yr'.\n",
    "    '''\n",
    "    global ticker, url_all, headlines, dates, news, urls, sources\n",
    "    \n",
    "    urlyr = \"https://www.moneycontrol.com/stocks/company_info/stock_news.php?sc_id=\" + urlsplit + \"&durationType=Y&Year={}\"\n",
    "    url = \"https://www.moneycontrol.com/stocks/company_info/stock_news.php?sc_id={}&scat=&pageno={}&next=0&durationType=Y&Year={}&duration=1&news_type=\"\n",
    "    \n",
    "    soup = BeautifulSoup(get(urlyr.format(yr)).text, 'lxml')\n",
    "    ticker = soup.select('div.FL.gry10')[0].text.split('|')[1].split(':')[1].strip()\n",
    "    result_max = len(soup.select('div.pages.MR10.MT15')[0].select('a')) + 1\n",
    "    \n",
    "    url_all = [url.format(urlsplit, i, yr) for i in range(1, result_max+1)]\n",
    "    headlines, dates, news, urls, sources = [], [], [], [], []\n",
    "    print(\"Total number of result pages for\", ticker, \"in the year\", yr, \":\", result_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getnewslinks():\n",
    "    '''\n",
    "    Function to scrape news headlines, urls, publish dates etc.\n",
    "    '''\n",
    "    print(\"[INFO] Extracting Links...\")\n",
    "\n",
    "    for src in tqdm(url_all):\n",
    "\n",
    "        try:\n",
    "            soup = BeautifulSoup(get(src).text, 'lxml')\n",
    "\n",
    "            # Extracts the Headlines\n",
    "            try:\n",
    "                headline = [script.text.strip() for script in soup.select('a.g_14bl')]\n",
    "                headlines.extend(headline)\n",
    "            except:\n",
    "                print('Exception in Headline')\n",
    "                headlines.extend(None)\n",
    "\n",
    "            # Extracts the urls\n",
    "            try:\n",
    "                source = [\"https://www.moneycontrol.com\"+script.get('href') for script in soup.select('a.g_14bl')]\n",
    "                urls.extend(source)\n",
    "            except:\n",
    "                print('Exception in url')\n",
    "                urls.extend(None)\n",
    "\n",
    "            # Extracts the published dates\n",
    "            try:\n",
    "                dateline = [str(parser.parse(script.text.split('|')[1].strip())).split()[0] for script in soup.select('p.PT3.a_10dgry')]\n",
    "                dates.extend(dateline)\n",
    "            except:\n",
    "                print('Exception in dateline')\n",
    "                dates.extend(None)\n",
    "\n",
    "            # Extracts the bylines\n",
    "            try:\n",
    "                bylines = [script.select('span.a_2_10bl')[0].text.strip() if len(script.select('span.a_2_10bl'))==1 else None\n",
    "                           for script in soup.select('p.PT3.a_10dgry')]\n",
    "                sources.extend(bylines)\n",
    "            except:\n",
    "                print('Exception in bylines')\n",
    "                sources.extend(None)\n",
    "\n",
    "        except:\n",
    "            print(\"Exception occurred in url : \", src)\n",
    "            break\n",
    "\n",
    "    print(\"[INFO] Links Extracted.\")\n",
    "    print(\"Total No. of Pages to be Scraped = \", len(urls))\n",
    "    print(\"Oldest Available Article: \", min(dates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getarticles(thres=20):\n",
    "    '''\n",
    "    Function to scrape news articles. Any paragraph with words less than 'thres' will not be considered.\n",
    "    '''\n",
    "    print(\"[INFO] Extracting Articles...\")\n",
    "\n",
    "    for src in tqdm(urls):\n",
    "        try:\n",
    "            # Parse the url to NewsPage\n",
    "            soup = BeautifulSoup(get(src).text, 'lxml')\n",
    "\n",
    "            # Extracts the news articles\n",
    "            try:\n",
    "                news_article = '.'.join([scrape.text.strip() for scrape in soup.select(\"div.arti-flow\")[0].select(\"p\")\n",
    "                                         if scrape.text.split() >= thres])\n",
    "                news.append(news_article)\n",
    "            except:\n",
    "                news.append(None)\n",
    "\n",
    "        except:\n",
    "            print(\"Exception occurred in url : \", src)\n",
    "            news.append(None)\n",
    "\n",
    "    print(\"[INFO] Articles Extracted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chkdata():\n",
    "    '''\n",
    "    Function to check for any missing values in the Dataframe and drop it.\n",
    "    '''\n",
    "    global df\n",
    "    df = pd.DataFrame({'Headlines': headlines,\n",
    "                       'Articles': news,\n",
    "                       'Published_Dates': dates,\n",
    "                       'Source_URLs': urls,\n",
    "                       'ByLines' : sources\n",
    "                       })\n",
    "    print(\"Missing Info in Scraped Data :\")\n",
    "    print(df.isna().sum())\n",
    "    df=df.dropna(axis = 0)\n",
    "    print(\"Total Usable Scraped Data : \", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def savefile(tickr,yr):\n",
    "    '''\n",
    "    Function to save the scraped data as pickle file.\n",
    "    '''\n",
    "    # df.to_csv(\"news_mcontrol_\"+ tickr + \"_\" + str(yr) + \".csv\")\n",
    "    df.to_pickle(\"news_mcontrol_\"+ tickr + \"_\" + str(yr) + \".pkl\")\n",
    "    print(\"Data saved for\", tickr, \"for year\",yr, \".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nifty50 Extraction Search Count : 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of result pages for RELIANCE in the year 2020 : 8\n",
      "[INFO] Extracting Links...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:24<00:00,  3.10s/it]\n",
      "  0%|                                                                                          | 0/155 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Links Extracted.\n",
      "Total No. of Pages to be Scraped =  155\n",
      "Oldest Available Article:  2020-05-04\n",
      "[INFO] Extracting Articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 155/155 [04:51<00:00,  1.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Articles Extracted.\n",
      "Missing Info in Scraped Data :\n",
      "Headlines            0\n",
      "Articles           155\n",
      "Published_Dates      0\n",
      "Source_URLs          0\n",
      "ByLines              0\n",
      "dtype: int64\n",
      "Total Usable Scraped Data :  (0, 5)\n",
      "Data saved for RELIANCE for year 2020 .\n",
      "Nifty50 Extraction Search Count : 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of result pages for HDFCBANK in the year 2020 : 6\n",
      "[INFO] Extracting Links...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:15<00:00,  2.60s/it]\n",
      "  0%|                                                                                          | 0/119 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Links Extracted.\n",
      "Total No. of Pages to be Scraped =  119\n",
      "Oldest Available Article:  2020-01-28\n",
      "[INFO] Extracting Articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 119/119 [03:49<00:00,  1.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Articles Extracted.\n",
      "Missing Info in Scraped Data :\n",
      "Headlines            0\n",
      "Articles           119\n",
      "Published_Dates      0\n",
      "Source_URLs          0\n",
      "ByLines              0\n",
      "dtype: int64\n",
      "Total Usable Scraped Data :  (0, 5)\n",
      "Data saved for HDFCBANK for year 2020 .\n",
      "Nifty50 Extraction Search Count : 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of result pages for INFY in the year 2020 : 6\n",
      "[INFO] Extracting Links...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:23<00:00,  3.99s/it]\n",
      "  0%|                                                                                          | 0/120 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Links Extracted.\n",
      "Total No. of Pages to be Scraped =  120\n",
      "Oldest Available Article:  2020-03-03\n",
      "[INFO] Extracting Articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 120/120 [04:52<00:00,  2.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Articles Extracted.\n",
      "Missing Info in Scraped Data :\n",
      "Headlines            0\n",
      "Articles           120\n",
      "Published_Dates      0\n",
      "Source_URLs          0\n",
      "ByLines              0\n",
      "dtype: int64\n",
      "Total Usable Scraped Data :  (0, 5)\n",
      "Data saved for INFY for year 2020 .\n",
      "Nifty50 Extraction Search Count : 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of result pages for HDFC in the year 2020 : 3\n",
      "[INFO] Extracting Links...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:16<00:00,  5.43s/it]\n",
      "  0%|                                                                                           | 0/57 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Links Extracted.\n",
      "Total No. of Pages to be Scraped =  57\n",
      "Oldest Available Article:  2020-03-05\n",
      "[INFO] Extracting Articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 57/57 [01:57<00:00,  2.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Articles Extracted.\n",
      "Missing Info in Scraped Data :\n",
      "Headlines           0\n",
      "Articles           57\n",
      "Published_Dates     0\n",
      "Source_URLs         0\n",
      "ByLines             0\n",
      "dtype: int64\n",
      "Total Usable Scraped Data :  (0, 5)\n",
      "Data saved for HDFC for year 2020 .\n",
      "Nifty50 Extraction Search Count : 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of result pages for TCS in the year 2020 : 5\n",
      "[INFO] Extracting Links...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:22<00:00,  4.57s/it]\n",
      "  0%|                                                                                          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Links Extracted.\n",
      "Total No. of Pages to be Scraped =  100\n",
      "Oldest Available Article:  2020-02-04\n",
      "[INFO] Extracting Articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [03:29<00:00,  2.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Articles Extracted.\n",
      "Missing Info in Scraped Data :\n",
      "Headlines            0\n",
      "Articles           100\n",
      "Published_Dates      0\n",
      "Source_URLs          0\n",
      "ByLines              0\n",
      "dtype: int64\n",
      "Total Usable Scraped Data :  (0, 5)\n",
      "Data saved for TCS for year 2020 .\n",
      "Nifty50 Extraction Search Count : 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of result pages for ICICIBANK in the year 2020 : 5\n",
      "[INFO] Extracting Links...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:19<00:00,  3.92s/it]\n",
      "  0%|                                                                                           | 0/97 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Links Extracted.\n",
      "Total No. of Pages to be Scraped =  97\n",
      "Oldest Available Article:  2020-04-01\n",
      "[INFO] Extracting Articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 97/97 [03:16<00:00,  2.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Articles Extracted.\n",
      "Missing Info in Scraped Data :\n",
      "Headlines           0\n",
      "Articles           96\n",
      "Published_Dates     0\n",
      "Source_URLs         0\n",
      "ByLines             0\n",
      "dtype: int64\n",
      "Total Usable Scraped Data :  (1, 5)\n",
      "Data saved for ICICIBANK for year 2020 .\n",
      "Nifty50 Extraction Search Count : 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of result pages for KOTAKBANK in the year 2020 : 3\n",
      "[INFO] Extracting Links...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:15<00:00,  5.01s/it]\n",
      "  0%|                                                                                           | 0/55 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Links Extracted.\n",
      "Total No. of Pages to be Scraped =  55\n",
      "Oldest Available Article:  2020-04-23\n",
      "[INFO] Extracting Articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 55/55 [02:06<00:00,  2.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Articles Extracted.\n",
      "Missing Info in Scraped Data :\n",
      "Headlines           0\n",
      "Articles           54\n",
      "Published_Dates     0\n",
      "Source_URLs         0\n",
      "ByLines             0\n",
      "dtype: int64\n",
      "Total Usable Scraped Data :  (1, 5)\n",
      "Data saved for KOTAKBANK for year 2020 .\n",
      "Nifty50 Extraction Search Count : 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of result pages for HINDUNILVR in the year 2020 : 5\n",
      "[INFO] Extracting Links...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:27<00:00,  5.50s/it]\n",
      "  0%|                                                                                          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Links Extracted.\n",
      "Total No. of Pages to be Scraped =  100\n",
      "Oldest Available Article:  2020-03-23\n",
      "[INFO] Extracting Articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [04:11<00:00,  2.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Articles Extracted.\n",
      "Missing Info in Scraped Data :\n",
      "Headlines           0\n",
      "Articles           98\n",
      "Published_Dates     0\n",
      "Source_URLs         0\n",
      "ByLines             0\n",
      "dtype: int64\n",
      "Total Usable Scraped Data :  (2, 5)\n",
      "Data saved for HINDUNILVR for year 2020 .\n",
      "Nifty50 Extraction Search Count : 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of result pages for ITC in the year 2020 : 3\n",
      "[INFO] Extracting Links...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:16<00:00,  5.43s/it]\n",
      "  0%|                                                                                           | 0/46 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Links Extracted.\n",
      "Total No. of Pages to be Scraped =  46\n",
      "Oldest Available Article:  2020-04-14\n",
      "[INFO] Extracting Articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 46/46 [01:15<00:00,  1.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Articles Extracted.\n",
      "Missing Info in Scraped Data :\n",
      "Headlines           0\n",
      "Articles           45\n",
      "Published_Dates     0\n",
      "Source_URLs         0\n",
      "ByLines             0\n",
      "dtype: int64\n",
      "Total Usable Scraped Data :  (1, 5)\n",
      "Data saved for ITC for year 2020 .\n",
      "Nifty50 Extraction Search Count : 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of result pages for LT in the year 2020 : 5\n",
      "[INFO] Extracting Links...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:20<00:00,  4.19s/it]\n",
      "  0%|                                                                                          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Links Extracted.\n",
      "Total No. of Pages to be Scraped =  100\n",
      "Oldest Available Article:  2020-01-27\n",
      "[INFO] Extracting Articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [02:45<00:00,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Articles Extracted.\n",
      "Missing Info in Scraped Data :\n",
      "Headlines           0\n",
      "Articles           99\n",
      "Published_Dates     0\n",
      "Source_URLs         0\n",
      "ByLines             0\n",
      "dtype: int64\n",
      "Total Usable Scraped Data :  (1, 5)\n",
      "Data saved for LT for year 2020 .\n",
      "Nifty50 Extraction Search Count : 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of result pages for AXISBANK in the year 2020 : 4\n",
      "[INFO] Extracting Links...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:16<00:00,  4.07s/it]\n",
      "  0%|                                                                                           | 0/69 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Links Extracted.\n",
      "Total No. of Pages to be Scraped =  69\n",
      "Oldest Available Article:  2020-04-02\n",
      "[INFO] Extracting Articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 69/69 [01:57<00:00,  1.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Articles Extracted.\n",
      "Missing Info in Scraped Data :\n",
      "Headlines           0\n",
      "Articles           69\n",
      "Published_Dates     0\n",
      "Source_URLs         0\n",
      "ByLines             0\n",
      "dtype: int64\n",
      "Total Usable Scraped Data :  (0, 5)\n",
      "Data saved for AXISBANK for year 2020 .\n",
      "Nifty50 Extraction Search Count : 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of result pages for BHARTIARTL in the year 2020 : 7\n",
      "[INFO] Extracting Links...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:28<00:00,  4.14s/it]\n",
      "  0%|                                                                                          | 0/138 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Links Extracted.\n",
      "Total No. of Pages to be Scraped =  138\n",
      "Oldest Available Article:  2020-02-17\n",
      "[INFO] Extracting Articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 138/138 [05:39<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Articles Extracted.\n",
      "Missing Info in Scraped Data :\n",
      "Headlines            0\n",
      "Articles           137\n",
      "Published_Dates      0\n",
      "Source_URLs          0\n",
      "ByLines              0\n",
      "dtype: int64\n",
      "Total Usable Scraped Data :  (1, 5)\n",
      "Data saved for BHARTIARTL for year 2020 .\n",
      "Nifty50 Extraction Search Count : 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of result pages for ASIANPAINT in the year 2020 : 3\n",
      "[INFO] Extracting Links...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:15<00:00,  5.01s/it]\n",
      "  0%|                                                                                           | 0/52 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Links Extracted.\n",
      "Total No. of Pages to be Scraped =  52\n",
      "Oldest Available Article:  2020-01-23\n",
      "[INFO] Extracting Articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 52/52 [02:14<00:00,  2.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Articles Extracted.\n",
      "Missing Info in Scraped Data :\n",
      "Headlines           0\n",
      "Articles           52\n",
      "Published_Dates     0\n",
      "Source_URLs         0\n",
      "ByLines             0\n",
      "dtype: int64\n",
      "Total Usable Scraped Data :  (0, 5)\n",
      "Data saved for ASIANPAINT for year 2020 .\n",
      "Nifty50 Extraction Search Count : 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of result pages for MARUTI in the year 2020 : 10\n",
      "[INFO] Extracting Links...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:54<00:00,  5.44s/it]\n",
      "  0%|                                                                                          | 0/199 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Links Extracted.\n",
      "Total No. of Pages to be Scraped =  199\n",
      "Oldest Available Article:  2020-01-22\n",
      "[INFO] Extracting Articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 199/199 [06:33<00:00,  1.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Articles Extracted.\n",
      "Missing Info in Scraped Data :\n",
      "Headlines            0\n",
      "Articles           197\n",
      "Published_Dates      0\n",
      "Source_URLs          0\n",
      "ByLines              0\n",
      "dtype: int64\n",
      "Total Usable Scraped Data :  (2, 5)\n",
      "Data saved for MARUTI for year 2020 .\n",
      "Nifty50 Extraction Search Count : 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of result pages for HCLTECH in the year 2020 : 4\n",
      "[INFO] Extracting Links...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:15<00:00,  3.93s/it]\n",
      "  0%|                                                                                           | 0/75 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Links Extracted.\n",
      "Total No. of Pages to be Scraped =  75\n",
      "Oldest Available Article:  2020-01-22\n",
      "[INFO] Extracting Articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 75/75 [02:02<00:00,  1.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Articles Extracted.\n",
      "Missing Info in Scraped Data :\n",
      "Headlines           0\n",
      "Articles           75\n",
      "Published_Dates     0\n",
      "Source_URLs         0\n",
      "ByLines             0\n",
      "dtype: int64\n",
      "Total Usable Scraped Data :  (0, 5)\n",
      "Data saved for HCLTECH for year 2020 .\n",
      "Nifty50 Extraction Search Count : 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of result pages for BAJFINANCE in the year 2020 : 2\n",
      "[INFO] Extracting Links...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:08<00:00,  4.45s/it]\n",
      "  0%|                                                                                           | 0/26 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Links Extracted.\n",
      "Total No. of Pages to be Scraped =  26\n",
      "Oldest Available Article:  2020-05-19\n",
      "[INFO] Extracting Articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 26/26 [00:43<00:00,  1.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Articles Extracted.\n",
      "Missing Info in Scraped Data :\n",
      "Headlines           0\n",
      "Articles           26\n",
      "Published_Dates     0\n",
      "Source_URLs         0\n",
      "ByLines             0\n",
      "dtype: int64\n",
      "Total Usable Scraped Data :  (0, 5)\n",
      "Data saved for BAJFINANCE for year 2020 .\n",
      "Nifty50 Extraction Search Count : 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of result pages for SBIN in the year 2020 : 10\n",
      "[INFO] Extracting Links...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:45<00:00,  4.52s/it]\n",
      "  0%|                                                                                          | 0/193 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Links Extracted.\n",
      "Total No. of Pages to be Scraped =  193\n",
      "Oldest Available Article:  2020-03-16\n",
      "[INFO] Extracting Articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 193/193 [06:24<00:00,  1.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Articles Extracted.\n",
      "Missing Info in Scraped Data :\n",
      "Headlines            0\n",
      "Articles           193\n",
      "Published_Dates      0\n",
      "Source_URLs          0\n",
      "ByLines              0\n",
      "dtype: int64\n",
      "Total Usable Scraped Data :  (0, 5)\n",
      "Data saved for SBIN for year 2020 .\n",
      "Nifty50 Extraction Search Count : 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of result pages for DRREDDY in the year 2020 : 4\n",
      "[INFO] Extracting Links...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:20<00:00,  5.11s/it]\n",
      "  0%|                                                                                           | 0/78 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Links Extracted.\n",
      "Total No. of Pages to be Scraped =  78\n",
      "Oldest Available Article:  2020-02-10\n",
      "[INFO] Extracting Articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 78/78 [03:08<00:00,  2.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Articles Extracted.\n",
      "Missing Info in Scraped Data :\n",
      "Headlines           0\n",
      "Articles           78\n",
      "Published_Dates     0\n",
      "Source_URLs         0\n",
      "ByLines             0\n",
      "dtype: int64\n",
      "Total Usable Scraped Data :  (0, 5)\n",
      "Data saved for DRREDDY for year 2020 .\n",
      "Nifty50 Extraction Search Count : 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of result pages for M&M in the year 2020 : 5\n",
      "[INFO] Extracting Links...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:25<00:00,  5.17s/it]\n",
      "  0%|                                                                                           | 0/99 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Links Extracted.\n",
      "Total No. of Pages to be Scraped =  99\n",
      "Oldest Available Article:  2020-02-11\n",
      "[INFO] Extracting Articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 99/99 [04:00<00:00,  2.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Articles Extracted.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "arrays must all be same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-0e4360028ced>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mgetnewslinks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mgetarticles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mchkdata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0msavefile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mticker\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-7fe7dbab8029>\u001b[0m in \u001b[0;36mchkdata\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m                        \u001b[1;34m'Published_Dates'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdates\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m                        \u001b[1;34m'Source_URLs'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0murls\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m                        \u001b[1;34m'ByLines'\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0msources\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m                        })\n\u001b[0;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Missing Info in Scraped Data :\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\stockpredict\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    466\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    467\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 468\u001b[1;33m             \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    469\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    470\u001b[0m             \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\stockpredict\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36minit_dict\u001b[1;34m(data, index, columns, dtype)\u001b[0m\n\u001b[0;32m    281\u001b[0m             \u001b[0marr\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_datetime64tz_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m         ]\n\u001b[1;32m--> 283\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    284\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\stockpredict\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, arr_names, index, columns, dtype, verify_integrity)\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[1;31m# figure out the index, if necessary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m             \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     79\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m             \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\stockpredict\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36mextract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    395\u001b[0m             \u001b[0mlengths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_lengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 397\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"arrays must all be same length\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    398\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    399\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhave_dicts\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: arrays must all be same length"
     ]
    }
   ],
   "source": [
    "# Scraping 2020 news articles for all the companies listed in Nifty50\n",
    "\n",
    "yr = 2020\n",
    "\n",
    "for i, sstring in enumerate(Substring):\n",
    "    print(\"Nifty50 Extraction Search Count :\",i+1)\n",
    "    initialize(yr, sstring)\n",
    "    getnewslinks()\n",
    "    getarticles()\n",
    "    chkdata()\n",
    "    savefile(ticker, yr)\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nifty50 Extraction Search Count : 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of result pages for M&M in the year 2020 : 5\n",
      "[INFO] Extracting Links...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:21<00:00,  4.29s/it]\n",
      "  0%|                                                                                           | 0/99 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Links Extracted.\n",
      "Total No. of Pages to be Scraped =  99\n",
      "Oldest Available Article:  2020-02-11\n",
      "[INFO] Extracting Articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 99/99 [02:55<00:00,  1.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Articles Extracted.\n",
      "Missing Info in Scraped Data :\n",
      "Headlines           0\n",
      "Articles           96\n",
      "Published_Dates     0\n",
      "Source_URLs         0\n",
      "ByLines             1\n",
      "dtype: int64\n",
      "Total Usable Scraped Data :  (3, 5)\n",
      "Data saved for M&M for year 2020 .\n"
     ]
    }
   ],
   "source": [
    "# Scraping 2020 news articles for all the companies listed in Nifty50\n",
    "\n",
    "yr = 2020\n",
    "\n",
    "for i, sstring in enumerate(Substring):\n",
    "    if i==18:\n",
    "        print(\"Nifty50 Extraction Search Count :\",i+1)\n",
    "        initialize(yr, sstring)\n",
    "        getnewslinks()\n",
    "        getarticles()\n",
    "        chkdata()\n",
    "        savefile(ticker, yr)\n",
    "        time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nifty50 Extraction Search Count : 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of result pages for NESTLEIND in the year 2020 : 2\n",
      "[INFO] Extracting Links...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:07<00:00,  3.73s/it]\n",
      "  0%|                                                                                           | 0/26 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Links Extracted.\n",
      "Total No. of Pages to be Scraped =  26\n",
      "Oldest Available Article:  2020-05-12\n",
      "[INFO] Extracting Articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 26/26 [00:44<00:00,  1.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Articles Extracted.\n",
      "Missing Info in Scraped Data :\n",
      "Headlines           0\n",
      "Articles           26\n",
      "Published_Dates     0\n",
      "Source_URLs         0\n",
      "ByLines             0\n",
      "dtype: int64\n",
      "Total Usable Scraped Data :  (0, 5)\n",
      "Data saved for NESTLEIND for year 2020 .\n",
      "Nifty50 Extraction Search Count : 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of result pages for SUNPHARMA in the year 2020 : 3\n",
      "[INFO] Extracting Links...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:11<00:00,  3.80s/it]\n",
      "  0%|                                                                                           | 0/52 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Links Extracted.\n",
      "Total No. of Pages to be Scraped =  52\n",
      "Oldest Available Article:  2020-05-23\n",
      "[INFO] Extracting Articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 52/52 [02:00<00:00,  2.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Articles Extracted.\n",
      "Missing Info in Scraped Data :\n",
      "Headlines           0\n",
      "Articles           52\n",
      "Published_Dates     0\n",
      "Source_URLs         0\n",
      "ByLines             0\n",
      "dtype: int64\n",
      "Total Usable Scraped Data :  (0, 5)\n",
      "Data saved for SUNPHARMA for year 2020 .\n",
      "Nifty50 Extraction Search Count : 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of result pages for TITAN in the year 2020 : 3\n",
      "[INFO] Extracting Links...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:18<00:00,  6.29s/it]\n",
      "  0%|                                                                                           | 0/52 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Links Extracted.\n",
      "Total No. of Pages to be Scraped =  52\n",
      "Oldest Available Article:  2020-02-07\n",
      "[INFO] Extracting Articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 52/52 [02:13<00:00,  2.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Articles Extracted.\n",
      "Missing Info in Scraped Data :\n",
      "Headlines           0\n",
      "Articles           52\n",
      "Published_Dates     0\n",
      "Source_URLs         0\n",
      "ByLines             0\n",
      "dtype: int64\n",
      "Total Usable Scraped Data :  (0, 5)\n",
      "Data saved for TITAN for year 2020 .\n",
      "Nifty50 Extraction Search Count : 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of result pages for TECHM in the year 2020 : 3\n",
      "[INFO] Extracting Links...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:18<00:00,  6.17s/it]\n",
      "  0%|                                                                                           | 0/48 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Links Extracted.\n",
      "Total No. of Pages to be Scraped =  48\n",
      "Oldest Available Article:  2020-04-08\n",
      "[INFO] Extracting Articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 48/48 [02:02<00:00,  2.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Articles Extracted.\n",
      "Missing Info in Scraped Data :\n",
      "Headlines           0\n",
      "Articles           48\n",
      "Published_Dates     0\n",
      "Source_URLs         0\n",
      "ByLines             0\n",
      "dtype: int64\n",
      "Total Usable Scraped Data :  (0, 5)\n",
      "Data saved for TECHM for year 2020 .\n",
      "Nifty50 Extraction Search Count : 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of result pages for ULTRACEMCO in the year 2020 : 3\n",
      "[INFO] Extracting Links...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:16<00:00,  5.60s/it]\n",
      "  0%|                                                                                           | 0/42 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Links Extracted.\n",
      "Total No. of Pages to be Scraped =  42\n",
      "Oldest Available Article:  2020-05-20\n",
      "[INFO] Extracting Articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 42/42 [01:48<00:00,  2.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Articles Extracted.\n",
      "Missing Info in Scraped Data :\n",
      "Headlines           0\n",
      "Articles           42\n",
      "Published_Dates     0\n",
      "Source_URLs         0\n",
      "ByLines             1\n",
      "dtype: int64\n",
      "Total Usable Scraped Data :  (0, 5)\n",
      "Data saved for ULTRACEMCO for year 2020 .\n",
      "Nifty50 Extraction Search Count : 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of result pages for WIPRO in the year 2020 : 4\n",
      "[INFO] Extracting Links...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:20<00:00,  5.23s/it]\n",
      "  0%|                                                                                           | 0/71 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Links Extracted.\n",
      "Total No. of Pages to be Scraped =  71\n",
      "Oldest Available Article:  2020-04-07\n",
      "[INFO] Extracting Articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 71/71 [03:28<00:00,  2.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Articles Extracted.\n",
      "Missing Info in Scraped Data :\n",
      "Headlines           0\n",
      "Articles           71\n",
      "Published_Dates     0\n",
      "Source_URLs         0\n",
      "ByLines             0\n",
      "dtype: int64\n",
      "Total Usable Scraped Data :  (0, 5)\n",
      "Data saved for WIPRO for year 2020 .\n",
      "Nifty50 Extraction Search Count : 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of result pages for BRITANNIA in the year 2020 : 3\n",
      "[INFO] Extracting Links...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:17<00:00,  5.82s/it]\n",
      "  0%|                                                                                           | 0/52 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Links Extracted.\n",
      "Total No. of Pages to be Scraped =  52\n",
      "Oldest Available Article:  2020-03-26\n",
      "[INFO] Extracting Articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 52/52 [02:19<00:00,  2.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Articles Extracted.\n",
      "Missing Info in Scraped Data :\n",
      "Headlines           0\n",
      "Articles           52\n",
      "Published_Dates     0\n",
      "Source_URLs         0\n",
      "ByLines             0\n",
      "dtype: int64\n",
      "Total Usable Scraped Data :  (0, 5)\n",
      "Data saved for BRITANNIA for year 2020 .\n",
      "Nifty50 Extraction Search Count : 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of result pages for HDFCLIFE in the year 2020 : 2\n",
      "[INFO] Extracting Links...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:11<00:00,  5.57s/it]\n",
      "  0%|                                                                                           | 0/34 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Links Extracted.\n",
      "Total No. of Pages to be Scraped =  34\n",
      "Oldest Available Article:  2020-03-18\n",
      "[INFO] Extracting Articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 34/34 [01:31<00:00,  2.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Articles Extracted.\n",
      "Missing Info in Scraped Data :\n",
      "Headlines           0\n",
      "Articles           33\n",
      "Published_Dates     0\n",
      "Source_URLs         0\n",
      "ByLines             0\n",
      "dtype: int64\n",
      "Total Usable Scraped Data :  (1, 5)\n",
      "Data saved for HDFCLIFE for year 2020 .\n",
      "Nifty50 Extraction Search Count : 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of result pages for POWERGRID in the year 2020 : 2\n",
      "[INFO] Extracting Links...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:13<00:00,  6.82s/it]\n",
      "  0%|                                                                                           | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Links Extracted.\n",
      "Total No. of Pages to be Scraped =  20\n",
      "Oldest Available Article:  2020-01-14\n",
      "[INFO] Extracting Articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:51<00:00,  2.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Articles Extracted.\n",
      "Missing Info in Scraped Data :\n",
      "Headlines           0\n",
      "Articles           20\n",
      "Published_Dates     0\n",
      "Source_URLs         0\n",
      "ByLines             0\n",
      "dtype: int64\n",
      "Total Usable Scraped Data :  (0, 5)\n",
      "Data saved for POWERGRID for year 2020 .\n",
      "Nifty50 Extraction Search Count : 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of result pages for NTPC in the year 2020 : 3\n",
      "[INFO] Extracting Links...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:16<00:00,  5.64s/it]\n",
      "  0%|                                                                                           | 0/60 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Links Extracted.\n",
      "Total No. of Pages to be Scraped =  60\n",
      "Oldest Available Article:  2020-01-01\n",
      "[INFO] Extracting Articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 60/60 [02:42<00:00,  2.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Articles Extracted.\n",
      "Missing Info in Scraped Data :\n",
      "Headlines           0\n",
      "Articles           60\n",
      "Published_Dates     0\n",
      "Source_URLs         0\n",
      "ByLines             0\n",
      "dtype: int64\n",
      "Total Usable Scraped Data :  (0, 5)\n",
      "Data saved for NTPC for year 2020 .\n",
      "Nifty50 Extraction Search Count : 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of result pages for HEROMOTOCO in the year 2020 : 5\n",
      "[INFO] Extracting Links...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:28<00:00,  5.74s/it]\n",
      "  0%|                                                                                           | 0/88 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Links Extracted.\n",
      "Total No. of Pages to be Scraped =  88\n",
      "Oldest Available Article:  2020-03-23\n",
      "[INFO] Extracting Articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 88/88 [03:39<00:00,  2.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Articles Extracted.\n",
      "Missing Info in Scraped Data :\n",
      "Headlines           0\n",
      "Articles           88\n",
      "Published_Dates     0\n",
      "Source_URLs         0\n",
      "ByLines             0\n",
      "dtype: int64\n",
      "Total Usable Scraped Data :  (0, 5)\n",
      "Data saved for HEROMOTOCO for year 2020 .\n",
      "Nifty50 Extraction Search Count : 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of result pages for CIPLA in the year 2020 : 4\n",
      "[INFO] Extracting Links...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:21<00:00,  5.49s/it]\n",
      "  0%|                                                                                           | 0/64 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Links Extracted.\n",
      "Total No. of Pages to be Scraped =  64\n",
      "Oldest Available Article:  2020-03-26\n",
      "[INFO] Extracting Articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 64/64 [02:34<00:00,  2.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Articles Extracted.\n",
      "Missing Info in Scraped Data :\n",
      "Headlines           0\n",
      "Articles           63\n",
      "Published_Dates     0\n",
      "Source_URLs         0\n",
      "ByLines             0\n",
      "dtype: int64\n",
      "Total Usable Scraped Data :  (1, 5)\n",
      "Data saved for CIPLA for year 2020 .\n",
      "Nifty50 Extraction Search Count : 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of result pages for DIVISLAB in the year 2020 : 2\n",
      "[INFO] Extracting Links...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:15<00:00,  7.73s/it]\n",
      "  0%|                                                                                           | 0/22 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Links Extracted.\n",
      "Total No. of Pages to be Scraped =  22\n",
      "Oldest Available Article:  2020-02-01\n",
      "[INFO] Extracting Articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 22/22 [00:52<00:00,  2.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Articles Extracted.\n",
      "Missing Info in Scraped Data :\n",
      "Headlines           0\n",
      "Articles           22\n",
      "Published_Dates     0\n",
      "Source_URLs         0\n",
      "ByLines             0\n",
      "dtype: int64\n",
      "Total Usable Scraped Data :  (0, 5)\n",
      "Data saved for DIVISLAB for year 2020 .\n",
      "Nifty50 Extraction Search Count : 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of result pages for BAJAJ-AUTO in the year 2020 : 6\n",
      "[INFO] Extracting Links...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:32<00:00,  5.47s/it]\n",
      "  0%|                                                                                          | 0/106 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Links Extracted.\n",
      "Total No. of Pages to be Scraped =  106\n",
      "Oldest Available Article:  2020-02-04\n",
      "[INFO] Extracting Articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 106/106 [04:20<00:00,  2.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Articles Extracted.\n",
      "Missing Info in Scraped Data :\n",
      "Headlines            0\n",
      "Articles           105\n",
      "Published_Dates      0\n",
      "Source_URLs          0\n",
      "ByLines              0\n",
      "dtype: int64\n",
      "Total Usable Scraped Data :  (1, 5)\n",
      "Data saved for BAJAJ-AUTO for year 2020 .\n",
      "Nifty50 Extraction Search Count : 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of result pages for BAJAJFINSV in the year 2020 : 2\n",
      "[INFO] Extracting Links...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:13<00:00,  6.74s/it]\n",
      "  0%|                                                                                           | 0/27 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Links Extracted.\n",
      "Total No. of Pages to be Scraped =  27\n",
      "Oldest Available Article:  2020-01-29\n",
      "[INFO] Extracting Articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 27/27 [01:01<00:00,  2.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Articles Extracted.\n",
      "Missing Info in Scraped Data :\n",
      "Headlines           0\n",
      "Articles           27\n",
      "Published_Dates     0\n",
      "Source_URLs         0\n",
      "ByLines             0\n",
      "dtype: int64\n",
      "Total Usable Scraped Data :  (0, 5)\n",
      "Data saved for BAJAJFINSV for year 2020 .\n",
      "Nifty50 Extraction Search Count : 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of result pages for SBILIFE in the year 2020 : 2\n",
      "[INFO] Extracting Links...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:13<00:00,  6.75s/it]\n",
      "  0%|                                                                                           | 0/32 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Links Extracted.\n",
      "Total No. of Pages to be Scraped =  32\n",
      "Oldest Available Article:  2020-01-22\n",
      "[INFO] Extracting Articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [01:21<00:00,  2.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Articles Extracted.\n",
      "Missing Info in Scraped Data :\n",
      "Headlines           0\n",
      "Articles           32\n",
      "Published_Dates     0\n",
      "Source_URLs         0\n",
      "ByLines             0\n",
      "dtype: int64\n",
      "Total Usable Scraped Data :  (0, 5)\n",
      "Data saved for SBILIFE for year 2020 .\n",
      "Nifty50 Extraction Search Count : 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of result pages for EICHERMOT in the year 2020 : 3\n",
      "[INFO] Extracting Links...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:16<00:00,  5.37s/it]\n",
      "  0%|                                                                                           | 0/45 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Links Extracted.\n",
      "Total No. of Pages to be Scraped =  45\n",
      "Oldest Available Article:  2020-03-03\n",
      "[INFO] Extracting Articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 45/45 [01:47<00:00,  2.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Articles Extracted.\n",
      "Missing Info in Scraped Data :\n",
      "Headlines           0\n",
      "Articles           42\n",
      "Published_Dates     0\n",
      "Source_URLs         0\n",
      "ByLines             0\n",
      "dtype: int64\n",
      "Total Usable Scraped Data :  (3, 5)\n",
      "Data saved for EICHERMOT for year 2020 .\n",
      "Nifty50 Extraction Search Count : 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of result pages for INDUSINDBK in the year 2020 : 3\n",
      "[INFO] Extracting Links...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:16<00:00,  5.47s/it]\n",
      "  0%|                                                                                           | 0/46 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Links Extracted.\n",
      "Total No. of Pages to be Scraped =  46\n",
      "Oldest Available Article:  2020-04-29\n",
      "[INFO] Extracting Articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 46/46 [01:45<00:00,  2.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Articles Extracted.\n",
      "Missing Info in Scraped Data :\n",
      "Headlines           0\n",
      "Articles           46\n",
      "Published_Dates     0\n",
      "Source_URLs         0\n",
      "ByLines             0\n",
      "dtype: int64\n",
      "Total Usable Scraped Data :  (0, 5)\n",
      "Data saved for INDUSINDBK for year 2020 .\n",
      "Nifty50 Extraction Search Count : 38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of result pages for GRASIM in the year 2020 : 2\n",
      "[INFO] Extracting Links...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:14<00:00,  7.25s/it]\n",
      "  0%|                                                                                           | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Links Extracted.\n",
      "Total No. of Pages to be Scraped =  21\n",
      "Oldest Available Article:  2020-02-10\n",
      "[INFO] Extracting Articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 21/21 [01:28<00:00,  4.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Articles Extracted.\n",
      "Missing Info in Scraped Data :\n",
      "Headlines           0\n",
      "Articles           21\n",
      "Published_Dates     0\n",
      "Source_URLs         0\n",
      "ByLines             0\n",
      "dtype: int64\n",
      "Total Usable Scraped Data :  (0, 5)\n",
      "Data saved for GRASIM for year 2020 .\n",
      "Nifty50 Extraction Search Count : 39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of result pages for BPCL in the year 2020 : 3\n",
      "[INFO] Extracting Links...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:16<00:00,  5.63s/it]\n",
      "  0%|                                                                                           | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Links Extracted.\n",
      "Total No. of Pages to be Scraped =  49\n",
      "Oldest Available Article:  2020-02-14\n",
      "[INFO] Extracting Articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 49/49 [02:03<00:00,  2.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Articles Extracted.\n",
      "Missing Info in Scraped Data :\n",
      "Headlines           0\n",
      "Articles           49\n",
      "Published_Dates     0\n",
      "Source_URLs         0\n",
      "ByLines             0\n",
      "dtype: int64\n",
      "Total Usable Scraped Data :  (0, 5)\n",
      "Data saved for BPCL for year 2020 .\n",
      "Nifty50 Extraction Search Count : 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of result pages for JSWSTEEL in the year 2020 : 3\n",
      "[INFO] Extracting Links...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:18<00:00,  6.17s/it]\n",
      "  0%|                                                                                           | 0/60 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Links Extracted.\n",
      "Total No. of Pages to be Scraped =  60\n",
      "Oldest Available Article:  2020-01-24\n",
      "[INFO] Extracting Articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 60/60 [02:38<00:00,  2.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Articles Extracted.\n",
      "Missing Info in Scraped Data :\n",
      "Headlines           0\n",
      "Articles           60\n",
      "Published_Dates     0\n",
      "Source_URLs         0\n",
      "ByLines             0\n",
      "dtype: int64\n",
      "Total Usable Scraped Data :  (0, 5)\n",
      "Data saved for JSWSTEEL for year 2020 .\n",
      "Nifty50 Extraction Search Count : 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of result pages for UPL in the year 2020 : 2\n",
      "[INFO] Extracting Links...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:10<00:00,  5.38s/it]\n",
      "  0%|                                                                                           | 0/22 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Links Extracted.\n",
      "Total No. of Pages to be Scraped =  22\n",
      "Oldest Available Article:  2020-05-25\n",
      "[INFO] Extracting Articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 22/22 [00:59<00:00,  2.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Articles Extracted.\n",
      "Missing Info in Scraped Data :\n",
      "Headlines           0\n",
      "Articles           22\n",
      "Published_Dates     0\n",
      "Source_URLs         0\n",
      "ByLines             0\n",
      "dtype: int64\n",
      "Total Usable Scraped Data :  (0, 5)\n",
      "Data saved for UPL for year 2020 .\n",
      "Nifty50 Extraction Search Count : 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of result pages for SHREECEM in the year 2020 : 2\n",
      "[INFO] Extracting Links...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:16<00:00,  8.30s/it]\n",
      "  0%|                                                                                           | 0/29 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Links Extracted.\n",
      "Total No. of Pages to be Scraped =  29\n",
      "Oldest Available Article:  2020-01-07\n",
      "[INFO] Extracting Articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [01:39<00:00,  3.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Articles Extracted.\n",
      "Missing Info in Scraped Data :\n",
      "Headlines           0\n",
      "Articles           29\n",
      "Published_Dates     0\n",
      "Source_URLs         0\n",
      "ByLines             1\n",
      "dtype: int64\n",
      "Total Usable Scraped Data :  (0, 5)\n",
      "Data saved for SHREECEM for year 2020 .\n",
      "Nifty50 Extraction Search Count : 43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of result pages for TATASTEEL in the year 2020 : 4\n",
      "[INFO] Extracting Links...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:23<00:00,  5.96s/it]\n",
      "  0%|                                                                                           | 0/77 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Links Extracted.\n",
      "Total No. of Pages to be Scraped =  77\n",
      "Oldest Available Article:  2020-01-27\n",
      "[INFO] Extracting Articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 77/77 [03:08<00:00,  2.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Articles Extracted.\n",
      "Missing Info in Scraped Data :\n",
      "Headlines           0\n",
      "Articles           77\n",
      "Published_Dates     0\n",
      "Source_URLs         0\n",
      "ByLines             0\n",
      "dtype: int64\n",
      "Total Usable Scraped Data :  (0, 5)\n",
      "Data saved for TATASTEEL for year 2020 .\n",
      "Nifty50 Extraction Search Count : 44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of result pages for HINDALCO in the year 2020 : 2\n",
      "[INFO] Extracting Links...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:14<00:00,  7.10s/it]\n",
      "  0%|                                                                                           | 0/32 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Links Extracted.\n",
      "Total No. of Pages to be Scraped =  32\n",
      "Oldest Available Article:  2020-02-12\n",
      "[INFO] Extracting Articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [01:14<00:00,  2.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Articles Extracted.\n",
      "Missing Info in Scraped Data :\n",
      "Headlines           0\n",
      "Articles           32\n",
      "Published_Dates     0\n",
      "Source_URLs         0\n",
      "ByLines             0\n",
      "dtype: int64\n",
      "Total Usable Scraped Data :  (0, 5)\n",
      "Data saved for HINDALCO for year 2020 .\n",
      "Nifty50 Extraction Search Count : 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of result pages for ADANIPORTS in the year 2020 : 2\n",
      "[INFO] Extracting Links...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:11<00:00,  5.86s/it]\n",
      "  0%|                                                                                           | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Links Extracted.\n",
      "Total No. of Pages to be Scraped =  30\n",
      "Oldest Available Article:  2020-02-04\n",
      "[INFO] Extracting Articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [01:19<00:00,  2.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Articles Extracted.\n",
      "Missing Info in Scraped Data :\n",
      "Headlines           0\n",
      "Articles           30\n",
      "Published_Dates     0\n",
      "Source_URLs         0\n",
      "ByLines             0\n",
      "dtype: int64\n",
      "Total Usable Scraped Data :  (0, 5)\n",
      "Data saved for ADANIPORTS for year 2020 .\n",
      "Nifty50 Extraction Search Count : 46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of result pages for ONGC in the year 2020 : 3\n",
      "[INFO] Extracting Links...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:17<00:00,  5.91s/it]\n",
      "  0%|                                                                                           | 0/54 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Links Extracted.\n",
      "Total No. of Pages to be Scraped =  54\n",
      "Oldest Available Article:  2020-01-05\n",
      "[INFO] Extracting Articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|█████████████████████████████████████████████████████████████████▎                | 43/54 [01:45<00:30,  2.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception occurred in url :  https://www.moneycontrol.com/news/business/ongc-starts-pumping-gasï»¿krishna-godavari-block_13588601.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 54/54 [02:09<00:00,  2.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Articles Extracted.\n",
      "Missing Info in Scraped Data :\n",
      "Headlines           0\n",
      "Articles           54\n",
      "Published_Dates     0\n",
      "Source_URLs         0\n",
      "ByLines             0\n",
      "dtype: int64\n",
      "Total Usable Scraped Data :  (0, 5)\n",
      "Data saved for ONGC for year 2020 .\n",
      "Nifty50 Extraction Search Count : 47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of result pages for COALINDIA in the year 2020 : 4\n",
      "[INFO] Extracting Links...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:22<00:00,  5.68s/it]\n",
      "  0%|                                                                                           | 0/62 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Links Extracted.\n",
      "Total No. of Pages to be Scraped =  62\n",
      "Oldest Available Article:  2020-05-16\n",
      "[INFO] Extracting Articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 62/62 [03:23<00:00,  3.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Articles Extracted.\n",
      "Missing Info in Scraped Data :\n",
      "Headlines           0\n",
      "Articles           62\n",
      "Published_Dates     0\n",
      "Source_URLs         0\n",
      "ByLines             0\n",
      "dtype: int64\n",
      "Total Usable Scraped Data :  (0, 5)\n",
      "Data saved for COALINDIA for year 2020 .\n",
      "Nifty50 Extraction Search Count : 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of result pages for TATAMOTORS in the year 2020 : 7\n",
      "[INFO] Extracting Links...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:37<00:00,  5.30s/it]\n",
      "  0%|                                                                                          | 0/140 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Links Extracted.\n",
      "Total No. of Pages to be Scraped =  140\n",
      "Oldest Available Article:  2020-02-05\n",
      "[INFO] Extracting Articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 140/140 [05:29<00:00,  2.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Articles Extracted.\n",
      "Missing Info in Scraped Data :\n",
      "Headlines            0\n",
      "Articles           139\n",
      "Published_Dates      0\n",
      "Source_URLs          0\n",
      "ByLines              0\n",
      "dtype: int64\n",
      "Total Usable Scraped Data :  (1, 5)\n",
      "Data saved for TATAMOTORS for year 2020 .\n",
      "Nifty50 Extraction Search Count : 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of result pages for IOC in the year 2020 : 4\n",
      "[INFO] Extracting Links...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:21<00:00,  5.39s/it]\n",
      "  0%|                                                                                           | 0/73 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Links Extracted.\n",
      "Total No. of Pages to be Scraped =  73\n",
      "Oldest Available Article:  2020-01-13\n",
      "[INFO] Extracting Articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 73/73 [04:39<00:00,  3.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Articles Extracted.\n",
      "Missing Info in Scraped Data :\n",
      "Headlines           0\n",
      "Articles           73\n",
      "Published_Dates     0\n",
      "Source_URLs         0\n",
      "ByLines             0\n",
      "dtype: int64\n",
      "Total Usable Scraped Data :  (0, 5)\n",
      "Data saved for IOC for year 2020 .\n",
      "Nifty50 Extraction Search Count : 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of result pages for GAIL in the year 2020 : 2\n",
      "[INFO] Extracting Links...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:10<00:00,  5.39s/it]\n",
      "  0%|                                                                                           | 0/34 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Links Extracted.\n",
      "Total No. of Pages to be Scraped =  34\n",
      "Oldest Available Article:  2020-01-17\n",
      "[INFO] Extracting Articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 34/34 [01:10<00:00,  2.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Articles Extracted.\n",
      "Missing Info in Scraped Data :\n",
      "Headlines           0\n",
      "Articles           34\n",
      "Published_Dates     0\n",
      "Source_URLs         0\n",
      "ByLines             0\n",
      "dtype: int64\n",
      "Total Usable Scraped Data :  (0, 5)\n",
      "Data saved for GAIL for year 2020 .\n"
     ]
    }
   ],
   "source": [
    "# Scraping 2020 news articles for all the companies listed in Nifty50\n",
    "\n",
    "yr = 2020\n",
    "\n",
    "for i, sstring in enumerate(Substring):\n",
    "    if i>=19:\n",
    "        print(\"Nifty50 Extraction Search Count :\",i+1)\n",
    "        initialize(yr, sstring)\n",
    "        getnewslinks()\n",
    "        getarticles()\n",
    "        chkdata()\n",
    "        savefile(ticker, yr)\n",
    "        time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The pages with blank Articles, if present, might have a different structure.\n",
    "# Some pages have no byline. Of these, some have video articles."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
