{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from requests import get\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from dateutil import parser\n",
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n"
     ]
    }
   ],
   "source": [
    "SearchString = \"ICICI%20BANK\"\n",
    "\n",
    "url = \"https://www.thehindu.com/search/?q=\" + SearchString + \"&order=DESC&sort=publishdate&pd=year&ct=text&s=business&page=\"\n",
    "\n",
    "soup = BeautifulSoup(get(url + \"1\").text, 'lxml')\n",
    "result_max = max([int(script.get('data-page-no')) for script in soup.select('a.page-link')])\n",
    "\n",
    "# Total number of result pages\n",
    "print(result_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_all = [url + str(i) for i in range(1, result_max+1)]\n",
    "headlines, sections, dates, news, urls, authors = [], [], [], [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/37 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Extracting links...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 37/37 [01:00<00:00,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Links Extracted.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] Extracting links...\")\n",
    "\n",
    "for src in tqdm(url_all):\n",
    "\n",
    "    try:\n",
    "        soup = BeautifulSoup(get(src).text, 'lxml')\n",
    "\n",
    "        # Extracts the Headlines\n",
    "        try:\n",
    "            headline = [script.text.strip() for script in soup.select('a.story-card75x1-text')]\n",
    "            headlines.extend(headline)\n",
    "        except:\n",
    "            headlines.extend(None)\n",
    "\n",
    "        # Extracts the urls\n",
    "        try:\n",
    "            source = [script.get('href') for script in soup.select('a.story-card75x1-text')]\n",
    "            urls.extend(source)\n",
    "        except:\n",
    "            urls.extend(None)\n",
    "\n",
    "        # Extracts the sections(markets, industry, business etc.)\n",
    "        try:\n",
    "            section = [script.text.strip() for script in soup.select('a.section-name')]\n",
    "            sections.extend(section)\n",
    "        except:\n",
    "            sections.extend(None)\n",
    "\n",
    "        # Extracts the published dates\n",
    "        try:\n",
    "            dateline = [str(parser.parse(script.text)).split()[0] for script in soup.select('span.dateline')]\n",
    "            dates.extend(dateline)\n",
    "        except:\n",
    "            dates.extend(None)\n",
    "\n",
    "        # Extracts the bylines\n",
    "#         try:\n",
    "#             bylines = [script.text.strip() for script in soup.select('a.story-card-33-author-name')]\n",
    "#             authors.extend(bylines)\n",
    "#             assert len(bylines)==12\n",
    "#         except:\n",
    "#             authors.extend(None)\n",
    "\n",
    "    except:\n",
    "        print(\"Exception occurred in url : \", src)\n",
    "        break\n",
    "\n",
    "print(\"[INFO] Links Extracted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total no. of pages scraped =  443\n",
      "Oldest available article:  2019-10-22\n"
     ]
    }
   ],
   "source": [
    "print(\"Total no. of pages scraped = \", len(urls))\n",
    "print(\"Oldest available article: \", min(dates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                          | 0/443 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Extracting articles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 443/443 [05:19<00:00,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Articles Extracted.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] Extracting articles...\")\n",
    "\n",
    "for src in tqdm(urls):\n",
    "    try:\n",
    "        # Parse the url to NewsPage\n",
    "        soup = BeautifulSoup(get(src).text, 'lxml')\n",
    "\n",
    "        # Extracts the news articles\n",
    "        try:\n",
    "            news_article = soup.find(id='content-body-14269002-' + re.findall(r\"\\d+\",src.split('/')[-1])[0]).text.strip()\n",
    "            news.append(news_article)\n",
    "        except:\n",
    "            news.append(None)\n",
    "\n",
    "        # Extracts the bylines\n",
    "        try:\n",
    "            bylines = [script.text.strip() for script in soup.select('a.auth-nm')]\n",
    "            authors.extend([' | '.join(bylines)])\n",
    "        except:\n",
    "            authors.extend(None)\n",
    "\n",
    "    except:\n",
    "        print(\"Exception occurred in url : \", src)\n",
    "        news.append(None)\n",
    "\n",
    "print(\"[INFO] Articles Extracted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Headlines            0\n",
      "Sections             0\n",
      "Articles           117\n",
      "Published_Dates      0\n",
      "Source_URLs          0\n",
      "ByLines              0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headlines</th>\n",
       "      <th>Sections</th>\n",
       "      <th>Articles</th>\n",
       "      <th>Published_Dates</th>\n",
       "      <th>Source_URLs</th>\n",
       "      <th>ByLines</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sensex ends 113 points higher; HCL Tech spurts 4%</td>\n",
       "      <td>Markets</td>\n",
       "      <td>Equity benchmarks Sensex and Nifty notched up ...</td>\n",
       "      <td>2020-10-20</td>\n",
       "      <td>https://www.thehindu.com/business/markets/sens...</td>\n",
       "      <td>PTI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sensex rises over 150 pts in early trade; Nift...</td>\n",
       "      <td>Markets</td>\n",
       "      <td>Equity benchmark Sensex advanced over 150 poin...</td>\n",
       "      <td>2020-10-20</td>\n",
       "      <td>https://www.thehindu.com/business/markets/sens...</td>\n",
       "      <td>PTI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Today's top business news: Stocks up, retail i...</td>\n",
       "      <td>Business</td>\n",
       "      <td>None</td>\n",
       "      <td>2020-10-20</td>\n",
       "      <td>https://www.thehindu.com/business/businesslive...</td>\n",
       "      <td>The Hindu Net Desk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sensex rallies 449 pts; Nifty tops 11,850</td>\n",
       "      <td>Markets</td>\n",
       "      <td>Equity benchmark Sensex rallied 449 points on ...</td>\n",
       "      <td>2020-10-19</td>\n",
       "      <td>https://www.thehindu.com/business/markets/sens...</td>\n",
       "      <td>PTI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sensex rallies over 300 points in early trade;...</td>\n",
       "      <td>Markets</td>\n",
       "      <td>Equity benchmark Sensex rallied over 300 point...</td>\n",
       "      <td>2020-10-19</td>\n",
       "      <td>https://www.thehindu.com/business/markets/sens...</td>\n",
       "      <td>PTI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Headlines  Sections  \\\n",
       "0  Sensex ends 113 points higher; HCL Tech spurts 4%   Markets   \n",
       "1  Sensex rises over 150 pts in early trade; Nift...   Markets   \n",
       "2  Today's top business news: Stocks up, retail i...  Business   \n",
       "3          Sensex rallies 449 pts; Nifty tops 11,850   Markets   \n",
       "4  Sensex rallies over 300 points in early trade;...   Markets   \n",
       "\n",
       "                                            Articles Published_Dates  \\\n",
       "0  Equity benchmarks Sensex and Nifty notched up ...      2020-10-20   \n",
       "1  Equity benchmark Sensex advanced over 150 poin...      2020-10-20   \n",
       "2                                               None      2020-10-20   \n",
       "3  Equity benchmark Sensex rallied 449 points on ...      2020-10-19   \n",
       "4  Equity benchmark Sensex rallied over 300 point...      2020-10-19   \n",
       "\n",
       "                                         Source_URLs             ByLines  \n",
       "0  https://www.thehindu.com/business/markets/sens...                 PTI  \n",
       "1  https://www.thehindu.com/business/markets/sens...                 PTI  \n",
       "2  https://www.thehindu.com/business/businesslive...  The Hindu Net Desk  \n",
       "3  https://www.thehindu.com/business/markets/sens...                 PTI  \n",
       "4  https://www.thehindu.com/business/markets/sens...                 PTI  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Headlines': headlines,\n",
    "                   'Sections' : sections,\n",
    "                   'Articles': news,\n",
    "                   'Published_Dates': dates,\n",
    "                   'Source_URLs': urls,\n",
    "                   'ByLines' : authors\n",
    "                   })\n",
    "\n",
    "# Checking for any missing values in the Dataframe\n",
    "print(df.isna().sum())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Data Scraped:  (326, 6)\n"
     ]
    }
   ],
   "source": [
    "# Dropping all the rows with empty values in any of the columns\n",
    "df=df.dropna(axis = 0)\n",
    "print(\"Total Data Scraped: \", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "sname = '_'.join(SearchString.split('%20'))\n",
    "# df.to_csv(\"news_thehindu_\"+ sname + \".csv\")\n",
    "df.to_pickle(\"news_thehindu_\"+ sname + \".pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
